{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Days@HES-SO Workshop MLOps","text":"<p>We are a team of passionate software engineers and data scientists from the Swiss AI Center. With expertise in both Machine Learning (ML) and DevOps, our mission is to provide a comprehensive guide for transitioning ML projects from experimentation to production.</p>"},{"location":"commands/","title":"Commands cheatsheet","text":"<p>Here is a summary of the most useful commands to know when you use the terminal:</p> <pre><code># List files and directories\nls\n\n# Change directory\ncd &lt;directory&gt;\n\n# Print the working directory\npwd\n\n# Create a directory\nmkdir &lt;directory&gt;\n\n# Remove a file\nrm &lt;file&gt;\n\n# Remove a directory\nrm -r &lt;directory&gt;\n\n# Copy a file\ncp &lt;source&gt; &lt;destination&gt;\n\n# Copy a directory\ncp -r &lt;source&gt; &lt;destination&gt;\n\n# Move a file\nmv &lt;source&gt; &lt;destination&gt;\n\n# Print the content of a file\ncat &lt;file&gt;\n\n# Print the content of a file with pagination\nless &lt;file&gt;\n</code></pre>"},{"location":"concept/","title":"Concept","text":"<p>Introduction to MLOps.</p>"},{"location":"concept/#what-is-mlops","title":"What is MLOps?","text":"<p>MLOps (short for \"Machine Learning Operations\"), is a discipline that focuses on improving the deployment, management, and monitoring of machine learning models in production environments.</p> <p>By merging the principles of software development and operations with data science and machine learning, MLOps aims to automate the entire machine learning lifecycle. This includes tasks such as data preparation, model training, deployment, and ongoing maintenance. The final objective is to ensure that the deployed models are accurate, scalable, and secure.</p> <p>However, achieving these goals involves more than just perfecting the machine learning models themselves. In reality, only a small fraction of real-world ML systems is composed of the ML code and model itself. The required necessary surrounding infrastructure for effective deployment and operation is much more vast and complex.</p> <p></p> <p>Implementing MLOps involves various tools and practices, including version control, continuous integration and deployment (CI/CD), infrastructure management, containerization, monitoring and logging frameworks. Through these mechanisms, MLOps enables efficient management of machine learning workflows, reducing errors and minimizing downtime.</p> <p>The ultimate goal of MLOps is to expedite the development and deployment of high-quality machine learning models, enabling organizations to reap the benefits of machine learning at scale, while maintaining reliability and stability in production environments.</p>"},{"location":"concept/#what-problems-does-mlops-aim-to-solve","title":"What problems does MLOps aim to solve?","text":"<p>MLOps tackles a range of challenges that arise when deploying machine learning models in production environments. Here are some key issues that MLOps aims to address:</p> <ul> <li>Scalability: Deploying resource-intensive machine learning models at scale   can be challenging. MLOps facilitates effective resource management, optimizing   model performance to handle large datasets and increasing demands efficiently.</li> <li>Reproducibility: Reproducing model results is crucial in machine learning.   MLOps ensures models can be replicated in production by providing mechanisms to   reproduce training data and maintain consistency across environments.</li> <li>Data management: Effective data management is essential for successful   machine learning. MLOps offers solutions to improve data management processes,   ensuring data is clean, properly labeled, and of high quality.</li> <li>Model drift: Machine learning models can experience drift over time due to   changing data or updates. MLOps aids in detecting and managing model drift,   enabling timely adjustments to maintain model accuracy and effectiveness.</li> <li>Security: Machine learning models are vulnerable to attacks, and   protecting them is paramount. MLOps incorporates security measures to safeguard   models from malicious actors and ensure data privacy and integrity.</li> </ul> <p>By addressing these challenges, MLOps accelerates the development and deployment of machine learning models while enhancing their overall quality and performance in production environments.</p>"},{"location":"concept/#why-would-mlops-be-useful-for-you","title":"Why would MLOps be useful for you?","text":"<p>MLOps offers several benefits for individuals involved in developing or deploying machine learning models in production environments. Here are the advantages you can expect:</p> <ul> <li>Enhanced efficiency: By automating various tasks like data preparation,   model training, and deployment, MLOps saves time and reduces errors, leading to   improved efficiency in the development and deployment process.</li> <li>Increased accuracy: MLOps ensures that machine learning models are trained   on high-quality data and optimized for production environments, resulting in   improved accuracy and performance of the models.</li> <li>Better scalability: MLOps helps scale machine learning models to handle   large datasets and meet growing demands, enabling expansion and accommodating   increased workload.</li> <li>Faster time to market: With MLOps, the development and deployment of   machine learning models can be accelerated, reducing the time it takes to   introduce new models to the market, gaining a competitive edge.</li> <li>Enhanced collaboration: MLOps fosters collaboration between different   teams involved in ML projects, such as data scientists, developers, and IT   operations. This promotes better communication, alignment, and synergy among   team members.</li> </ul> <p>Overall, MLOps simplifies the process of developing and deploying machine learning models, resulting in increased efficiency, accuracy, scalability, faster time to market, and improved collaboration. These advantages contribute to better outcomes and more successful machine learning projects.</p>"},{"location":"conclusion/","title":"Conclusion","text":"<p>Congratulations! You did it! You were able to convert a ML experiment with a traditional approach to a well-defined, well-documented workflow that can scale and serve a model to the outside world!</p> <p>Let's take the time to make a summary of what you have done.</p>"},{"location":"conclusion/#summary-of-what-you-have-done","title":"Summary of what you have done","text":"<ul> <li> The model can be reproduced</li> </ul> <p>Thanks to DVC, the steps to create the model are documented and can be executed in order to reproduce the model.</p> <ul> <li> The changes done to a model can be tracked</li> </ul> <p>Thanks to DVC, the changes done to a model can be tracked.</p> <ul> <li> The model can be used outside of the experiment context</li> </ul> <p>Thanks to BentoML, the model can be served and be used outside of the experiment context.</p>"},{"location":"conclusion/#going-further","title":"Going further","text":"<p>This workshop has been developed for the AI Days@HES-SO 2025 Conference. It is a highly condensed version of our main MLOps course, which is available at mlops.swiss-ai-center.ch.</p> <p>The main course goes much further and offers a more complete understanding of the subject, providing valuable knowledge and hands-on experience. We invite you to explore it for a deeper dive into MLOps.</p> <p>Happy learning! :)</p>"},{"location":"syllabus/","title":"Syllabus","text":"<p>What you will learn from this guide.</p> <ul> <li>Introduction - Learn about the concept behind MLOps.</li> <li>Part 1 - Local training - Learn how   to train a model locally using DVC.<ul> <li>Chapter 1.1 - Run a simple ML experiment with Jupyter Notebook</li> <li>Chapter 1.2 - Adapt and move the Jupyter Notebook to Python scripts</li> <li>Chapter 1.3 - Initialize Git and DVC for local training</li> </ul> </li> <li>Part 2 - Model evaluation - Learn   how to evaluate a model using DVC.<ul> <li>Chapter 2.1 - Reproduce the ML experiment with DVC</li> <li>Chapter 2.2 - Track model evolution with DVC</li> </ul> </li> <li>Part 3 - Serve the model -   Learn how to serve the model using BentoML and Docker.<ul> <li>Chapter 3.1 - Save and load the model with BentoML</li> <li>Chapter 3.2 - Serve the model locally with BentoML</li> <li>Chapter 3.3 - Build and publish the model with BentoML and Docker locally</li> </ul> </li> <li>Conclusion - Summary of what you have done and what is left   to be done.</li> </ul>"},{"location":"tools/","title":"Tools","text":"<p>Introduction to the tools used in this guide.</p>"},{"location":"tools/#what-are-the-tools-used-in-this-guide","title":"What are the tools used in this guide?","text":"<p>In this guide, you will use the following tools to demonstrate the MLOps process:</p> <ul> <li>Code management:  Git</li> <li>Package management:  pip</li> <li>Data management:  DVC</li> <li>Model reproducibility:  DVC</li> <li>Model serving and distributing:    BentoML and    Docker</li> </ul> <p>You will go into details about each tool in the following parts of this guide.</p>"},{"location":"wsl2/","title":"Preparing the Windows environment","text":"<p>This guide has been written with  macOS and  Linux operating systems in mind. If you use  Windows, you might encounter issues.</p> <p>This guide will help you to set up a Linux environment on your Windows computer to be able to follow the workshop (and beyond), through the Windows Subsystem for Linux.</p>"},{"location":"wsl2/#install-and-configure-windows-subsystem-for-linux-wsl","title":"Install and configure Windows Subsystem for Linux (WSL)","text":"<p>This section will guide you through the process of installing and configuring Windows Subsystem for Linux (WSL) on your Windows installation.</p>"},{"location":"wsl2/#install-wsl","title":"Install WSL","text":"<p>WSL is a compatibility layer for running Linux binary executables natively on Windows. It is a very useful tool for developers who want to use Linux tools and utilities on Windows.</p> <p>To install WSL, search \"PowerShell\" in the Start menu, right-click on it, and select \"Run as administrator\":</p> <p>Then, run the following command in the terminal:</p> <p>Warning</p> <p>If the following command displays the help message, proceed to the next section.</p> <pre><code># Install WSL without specifying a distribution\nwsl --install --no-distribution\n</code></pre> <p>The output should be similar to this:</p> <pre><code>Installing: Virtual Machine Platform\nVirtual Machine Platform has been installed.\nInstalling: Windows Subsystem for Linux\nWindows Subsystem for Linux has been installed.\nInstalling: Windows Subsystem for Linux\nWindows Subsystem for Linux has been installed.\nThe requested operation is successful. Changes will not be effective until the system is rebooted.\n</code></pre> <p>Restart your computer once the installation is complete.</p>"},{"location":"wsl2/#update-wsl","title":"Update WSL","text":"<p>WSL can still be in version 1 and must be updated to version 2.</p> <p>To do so, open PowerShell as administrator and run the following command in the terminal:</p> <pre><code># Check for WSL updates\nwsl --update\n</code></pre> <p>If there are updates available, you will be prompted to download and install them.</p> <p>Set the WSL default version to 2 by running the following command in the terminal:</p> <pre><code># Set WSL default version to 2\nwsl --set-default-version 2\n</code></pre> <p>The output should be similar to this:</p> <pre><code>For information on key differences with WSL 2 please visit https://aka.ms/wsl2\nThe operation completed successfully.\n</code></pre>"},{"location":"wsl2/#install-a-linux-distribution","title":"Install a Linux distribution","text":"<p>WSL supports multiple Linux distributions, but we recommend installing Ubuntu if you are not familiar with Linux as it is a very user-friendly distribution and is widely used.</p> <pre><code># Install Ubuntu\nwsl --install --distribution Ubuntu\n</code></pre> <p>Once the installation is complete, you can set up a username and password for the Ubuntu distribution.</p> <p>Tip</p> <p>While setting up your password, it is expected that you will not see any characters on the screen. This is a security feature of the terminal. Even though you do not see the characters you type (e.g., <code>p@ssw0rd</code>), they are still being entered. So, make sure to remember your password as you will need it later.</p> <p>We recommend using an username in lowercase letters without space for simplicity.</p> <p>Once you have set up your username and password, Ubuntu will be started, and you will be able to run Linux commands in the terminal.</p> <p>The output should be similar to this:</p> <pre><code>Installing: Ubuntu\nUbuntu has been installed.\nLaunching Ubuntu...\nInstalling, this may take a few minutes...\nPlease create a default UNIX user account. The username does not need to match your Windows username.\nFor more information visit: https://aka.ms/wslusers\nEnter new UNIX username: ludelafo\nNew password:\nRetype new password:\npasswd: password updated successfully\nInstallation successful!\nTo run a command as administrator (user \"root\"), use \"sudo &lt;command&gt;\".\nSee \"man sudo_root\" for details.\n\nWelcome to Ubuntu 22.04.3 LTS (GNU/Linux 5.10.102.1-microsoft-standard-WSL2 x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\nThis message is shown once a day. To disable it please create the\n/home/ludelafo/.hushlogin file.\nludelafo@win-10:~$\n</code></pre> <p>To exit the Ubuntu terminal, you can run the following command:</p> <pre><code># Exit the Ubuntu terminal\nexit\n</code></pre> <p>WSL is now installed and configured on your Windows machine. You can use it to run Linux commands and utilities on Windows.</p>"},{"location":"wsl2/#linux-and-windows-filesystems","title":"Linux and Windows filesystems","text":"<p>When you access the Ubuntu terminal, you will be in the home directory of your Ubuntu user. Your Ubuntu home directory is located in the <code>/home</code> directory. The <code>~</code> symbol represents the home directory of your Ubuntu user.</p> <p>You can access your Windows files in the <code>/mnt</code> directory. For example, you can access your Windows <code>C:\\Users</code> drive in the <code>/mnt/c/Users</code> directory, however, we do not recommend to manipulate your files from the File Explorer on Windows. Check the Tips and tricks section for more information.</p> <p>Windows has added an entry to the File Explorer sidebar for the Ubuntu distribution. You can access your Ubuntu files in the <code>\\\\wsl$\\Ubuntu\\home\\YOUR_USERNAME</code> directory.</p> <p>Danger</p> <p>We highly recommend to never manipulate your files from the File Explorer on Windows. Use the Ubuntu terminal instead to avoid permission issues and odd file behaviors.</p>"},{"location":"wsl2/#install-and-configure-windows-terminal","title":"Install and configure Windows Terminal","text":""},{"location":"wsl2/#install-windows-terminal","title":"Install Windows Terminal","text":"<p>Windows comes with a terminal application called \"Command Prompt\".</p> <p>It is a very basic terminal application that does not support many features that are available in modern terminal applications. Microsoft has developed a new terminal application called Windows Terminal that is available for Windows users.</p> <p>The Windows Terminal is a new, modern, fast, efficient, powerful, and productive terminal application for users of command-line tools and shells like Command Prompt, PowerShell, and WSL.</p> <p>You can download it from the Microsoft Store: Windows Terminal or the GitHub releases page: Windows Terminal Releases (download the <code>.msixbundle</code> file).</p> <p>Install it and open it.</p>"},{"location":"wsl2/#configure-windows-terminal","title":"Configure Windows Terminal","text":"<p>By default, Windows Terminal will open PowerShell. Now that you have installed Windows Terminal, you can configure it to open WSL by default.</p> <p>Access the settings by clicking on the down arrow in the title bar and selecting \"Settings\". Set the two following settings:</p> <ul> <li>Default profile: Ubuntu</li> <li>Default terminal application: Windows Terminal</li> </ul> <p>Press Save to save the settings.</p> <p>Close Windows Terminal and open it again. It should now open Ubuntu by default.</p> <p>You now have a modern terminal application that supports multiple tabs, multiple shells, and many other features.</p> <p>You now have access to a Linux distribution on your Windows machine. You can use it to run Linux commands and utilities on Windows.</p>"},{"location":"wsl2/#update-ubuntu","title":"Update Ubuntu","text":"<p>Before starting the installation of the development environment, make sure that your Ubuntu installation is up to date. You can update Ubuntu by running the following commands in the terminal. You might need to enter your password when running the commands:</p> <p>Tip</p> <p>The <code>sudo</code> command is used to run commands with superuser privileges. You will be prompted to enter your password when running a command with <code>sudo</code>.</p> <p>This is a security feature of Linux to prevent unauthorized access to the system.</p> <p>Tip</p> <p>All Linux distributions come with a package manager that is used to install, update, and remove packages. The package manager for Ubuntu is called <code>apt</code>.</p> <p>The package manager uses a package list to know which packages are available for installation. You can then install any package from the package list using the package manager.</p> <pre><code># Update the package list\nsudo apt update\n\n# Upgrade the installed packages\nsudo apt upgrade\n</code></pre> <p>Press <code>y</code> when prompted to confirm the upgrade.</p> <p>All packages will be upgraded to the latest version.</p>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/","title":"Chapter 1.1 - Run a simple ML experiment with Jupyter Notebook","text":""},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#introduction","title":"Introduction","text":"<p>As a recent addition to the ML team, your objective is to contribute to the development of a model capable of visually identifying planets or moons within our solar system from images.</p> <p>The data scientists of your team have been actively collaborating on a Jupyter Notebook, which they have readily shared with you. The dataset they have gathered comprises approximately 1,650 images capturing 11 distinct planets and moons. Each celestial body is represented by around 150 images, each taken from a unique angle.</p> <p>The training process is as follows:</p> <ul> <li>Preprocess the dataset</li> <li>Split the celestial bodies into training/testing datasets</li> <li>Train a model to classify the celestial bodies using the training dataset</li> <li>Evaluate the model's performance using metrics, training history, predictions   preview and a confusion matrix.</li> </ul> <p>Your primary objective is to enhance the team's workflow by implementing MLOps tools, documenting the procedures, tracking changes, and ensuring the model is accessible to others.</p> <p>In this chapter, you will learn how to:</p> <ol> <li>Set up the project directory</li> <li>Acquire the notebook</li> <li>Obtain the dataset</li> <li>Create a  Python environment to run the    experiment</li> <li>Launch the experiment locally for the first time</li> </ol> <p>The following diagram illustrates the control flow of the experiment at the end of this chapter:</p> <pre><code>flowchart\n    subgraph workspaceGraph[WORKSPACE]\n        data[data/raw] &lt;--&gt; notebook[notebook.ipynb]\n    end</code></pre> <p>Let's get started!</p>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#steps","title":"Steps","text":""},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#set-up-the-project-directory","title":"Set up the project directory","text":"<p>As a new team member, set up a project directory on your computer for this ground breaking ML experiment. This directory will serve as your working directory for this first chapter:</p> Execute the following command(s) in a terminal<pre><code># Create the working directory\nmkdir a-guide-to-mlops-jupyter-notebook\n\n# Switch to the working directory\ncd a-guide-to-mlops-jupyter-notebook\n</code></pre>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#download-the-notebook","title":"Download the notebook","text":"<p>Your colleague provided you the following URL to download an archive containing the Jupyter Notebook for this machine learning experiment:</p> Execute the following command(s) in a terminal<pre><code># Download the archive containing the Jupyter Notebook\nwget https://github.com/swiss-ai-center/a-guide-to-mlops/archive/refs/heads/jupyter-notebook.zip -O jupyter-notebook.zip\n</code></pre> <p>Unzip the Jupyter Notebook into your working directory:</p> Execute the following command(s) in a terminal<pre><code># Extract the Jupyter Notebook\nunzip jupyter-notebook.zip\n\n# Move the subdirectory files to the working directory\nmv a-guide-to-mlops-jupyter-notebook/* .\n\n# Remove the archive and the directory\nrm -r jupyter-notebook.zip a-guide-to-mlops-jupyter-notebook\n</code></pre>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#download-and-set-up-the-dataset","title":"Download and set up the dataset","text":"<p>Your colleague provided you the following URL to download an archive containing the dataset for this machine learning experiment:</p> Execute the following command(s) in a terminal<pre><code># Download the archive containing the dataset\nwget https://github.com/swiss-ai-center/a-guide-to-mlops/archive/refs/heads/data.zip -O data.zip\n</code></pre> <p>This archive must be decompressed and its contents be moved in the <code>data</code> directory in the working directory of the experiment:</p> Execute the following command(s) in a terminal<pre><code># Extract the dataset\nunzip data.zip\n\n# Move the `data.xml` file to the working directory\nmv a-guide-to-mlops-data/ data/\n\n# Remove the archive and the directory\nrm data.zip\n</code></pre>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#explore-the-notebook-and-dataset","title":"Explore the notebook and dataset","text":"<p>Examine the notebook and the dataset to get a better understanding of their contents.</p> <p>Your working directory should now look like this:</p> <pre><code>.\n\u251c\u2500\u2500 data # (1)!\n\u2502   \u251c\u2500\u2500 raw # (2)!\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 notebook.ipynb\n\u2514\u2500\u2500 requirements.txt\n</code></pre> <ol> <li>This, and all its sub-directory, is new.</li> <li>The <code>raw</code> directory include the unprocessed dataset images.</li> </ol>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#create-the-virtual-environment","title":"Create the virtual environment","text":"<p>Create the virtual environment and install necessary dependencies in your working directory:</p> Execute the following command(s) in a terminal<pre><code># Create the virtual environment\npython3.12 -m venv .venv\n\n# Activate the virtual environment\nsource .venv/bin/activate\n\n# Install the dependencies\npip install --requirement requirements.txt\n</code></pre>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#run-the-experiment","title":"Run the experiment","text":"<p>Awesome! You now have everything you need to run the experiment: the notebook and the dataset are in place, the virtual environment is ready; and you're ready to run the experiment for the first time.</p> <p>Launch the notebook:</p> Execute the following command(s) in a terminal<pre><code># Launch the experiment\njupyter-lab notebook.ipynb\n</code></pre> <p>A browser window should open with the Jupyter Notebook at http://localhost:8888/lab/tree/notebook.ipynb.</p> <p>You may notice all the previous outputs from the notebook might still be present. This is because the notebook was not cleared before being shared with you. This can be useful to see the results of previous runs.</p> <p>In most cases, however, it can also be a source of confusion. This is one of the limitations of the Jupyter Notebook, which make them not always easy to share with others.</p> <p>For the time being, execute each step of the notebook to train the model and evaluate its performance. Previous outputs will be overwritten.</p> <p>Ensure the experiment runs without errors. Once done, you can close the browser window. Shut down the Jupyter server by pressing Ctrl+C in the terminal, followed with Y and Enter.</p> <p>Exit the virtual environment with the following command:</p> Execute the following command(s) in a terminal<pre><code># Exit the virtual environment\ndeactivate\n</code></pre> <p>The Jupyter notebook serves as a valuable tool for consolidating an entire experiment into a single file, facilitating data visualization, and enabling the presentation of results. However, it does have severe limitations such as being challenging to share with others due to a lack of versioning capabilities, difficulty in reproducing the experiment, and the potential for data leaks and confusion from previous outputs.</p> <p>In the next chapter you will see how to address these issues.</p>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#summary","title":"Summary","text":"<p>Congratulations! You have successfully reproduced the experiment on your machine.</p> <p>In this chapter, you have:</p> <ol> <li>Created the working directory</li> <li>Acquired the codebase</li> <li>Obtained the dataset</li> <li>Set up a Python environment to run the experiment</li> <li>Executed the experiment locally for the first time</li> </ol> <p>However, you may have identified the following areas for improvement:</p> <ul> <li> Notebook still needs manual download</li> <li> Dataset still needs manual download and placement</li> <li> Steps to run the experiment were not documented</li> </ul> <p>In the next chapters, you will enhance the workflow to fix those issues.</p>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#state-of-the-mlops-process","title":"State of the MLOps process","text":"<ul> <li> Notebook can be run but is not adequate for production</li> <li> Codebase and dataset are not versioned</li> <li> Model steps rely on verbal communication and may be undocumented</li> <li> Changes to model are not easily visualized</li> <li> Model may have required artifacts that are forgotten or omitted in       saved/loaded state</li> <li> Model cannot be easily used from outside of the experiment context</li> </ul> <p>You will address these issues in the next chapters for improved efficiency and collaboration. Continue the guide to learn how.</p>"},{"location":"part-1-local-training/chapter-11-run-a-simple-ml-experiment-with-jupyter-notebook/#sources","title":"Sources","text":"<p>Highly inspired by:</p> <ul> <li>Planets and Moons Dataset - AI in Space - kaggle.com   community prediction competition.</li> </ul>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/","title":"Chapter 1.2 - Adapt and move the Jupyter Notebook to Python scripts","text":""},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#introduction","title":"Introduction","text":"<p>Jupyter Notebooks provide an interactive environment where code can be executed and results can be visualized. They combine code, text explanations, visualizations, and media in a single document, making it a flexible tool to document a ML experiment.</p> <p>However, they have severe limitations, such as challenges with reproducibility, scalability, experiment tracking, and standardization. Integrating Jupyter Notebooks into  Python scripts suitable for running ML experiments in a more modular and reproducible manner can help address these issues and enhance the overall ML development process.</p> <p> pip is the standard package manager for Python. It is used to install and manage dependencies in a Python environment.</p> <p>In this chapter, you will learn how to:</p> <ol> <li>Set up a Python environment using pip</li> <li>Adapt the content of the Jupyter Notebook into Python scripts</li> <li>Launch the experiment locally</li> </ol> <p>The following diagram illustrates the control flow of the experiment at the end of this chapter:</p> <pre><code>flowchart LR\n    subgraph workspaceGraph[WORKSPACE]\n        prepare[prepare.py] --&gt; train\n        train[train.py] --&gt; evaluate[evaluate.py]\n        params[params.yaml] -.- prepare\n        params -.- train\n        data[data/raw] --&gt; prepare\n    end\n    style data opacity:0.4,color:#7f7f7f80</code></pre> <p>Let's get started!</p>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#steps","title":"Steps","text":""},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#set-up-a-new-project-directory","title":"Set up a new project directory","text":"<p>For the rest of the guide, you will work in a new directory. This will allow you to use the Jupyter Notebook directory as a reference.</p> <p>Start by ensuring you have left the virtual environment created in the previous chapter:</p> Execute the following command(s) in a terminal<pre><code># Deactivate the virtual environment\ndeactivate\n</code></pre> <p>Next, exit from the current directory and create a new one:</p> Execute the following command(s) in a terminal<pre><code># Move back to the root directory\ncd ..\n\n# Create the new working directory\nmkdir a-guide-to-mlops\n\n# Switch to the new working directory\ncd a-guide-to-mlops\n</code></pre>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#set-up-the-dataset","title":"Set up the dataset","text":"<p>You will use the same dataset as in the previous chapter. Copy the <code>data</code> folder from the previous chapter to your new directory:</p> Execute the following command(s) in a terminal<pre><code># Copy the data folder from the previous chapter\ncp -r ../a-guide-to-mlops-jupyter-notebook/data .\n</code></pre>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#set-up-a-python-environment","title":"Set up a Python environment","text":"<p>Firstly, create the virtual environment:</p> Not familiar with virtual environments? Read this! <p>What are virtual environments?</p> <p>Python virtual environments are essential tools for managing dependencies and isolating project environments. They allow developers to create separate, self-contained environments for different projects, ensuring that each project has its own set of dependencies without interfering with one another.</p> <p>This is particularly important when working on multiple projects with different versions of libraries or packages.</p> <p>How do virtual environments work?</p> <p>Virtual environments work by creating a local directory that contains a Python interpreter and a copy of the desired Python packages. When activated, the virtual environment modifies the system's PATH variable to prioritize the interpreter and packages within the local directory.</p> <p>This ensures that when running Python commands, the system uses the specific interpreter and packages from the virtual environment, effectively isolating the project from the global Python installation.</p> <p>How to manage virtual environments?</p> <ul> <li>Create a virtual environment: <code>python3.12 -m venv .venv</code></li> <li>Activate the virtual environment: <code>source .venv/bin/activate</code></li> <li>Deactivate the virtual environment: <code>deactivate</code></li> </ul> <p>Conclusion</p> <p>Virtual environments are essential for dependency management and environment isolation. They ensure stability, reproducibility, and clean project separation. By using virtual environments, you achieve smoother collaboration, easier debugging, and reliable deployment.</p> Execute the following command(s) in a terminal<pre><code># Create the environment\npython3.12 -m venv .venv\n\n# Activate the environment\nsource .venv/bin/activate\n</code></pre> <p>Create a <code>requirements.txt</code> file to list the dependencies:</p> requirements.txt<pre><code>tensorflow==2.17.1\nmatplotlib==3.9.3\npyyaml==6.0.2\n</code></pre> <p>Install the dependencies:</p> Execute the following command(s) in a terminal<pre><code># Install the dependencies\npip install --requirement requirements.txt\n</code></pre> <p>Create a freeze file to list the dependencies with their versions to ensure that transitive dependencies are also listed. This will help with reproducibility:</p> Not familiar with freezing dependencies? Read this! <p>When working on Python projects, managing dependencies is crucial for maintaining a stable and reproducible development environment.</p> <p>Understanding requirements.txt</p> <p>The requirements.txt file is a commonly used approach to specify project dependencies. It lists all the high-level dependencies required for your project, including their specific versions. Each line in the file typically follows the format: <code>package_name==version</code>.</p> <p>Freezing dependencies</p> <p>Freezing dependencies refers to fixing the versions of all transitive dependencies, ensuring that the same versions are installed consistently across different environments. This is crucial for reproducibility, as it guarantees that everyone working on the project has the exact same dependencies.</p> <p>Separating high-level and transitive dependencies</p> <p>To better control and manage your project's dependencies, it's beneficial to separate high-level dependencies from transitive dependencies. This approach allows for clearer identification of the core functionality packages and their required versions, ensuring a more focused and stable development environment.</p> <ul> <li> <p><code>requirements.txt</code>: This file contains the high-level dependencies explicitly   required by your project. It should include packages necessary for your   project's core functionality while excluding packages that are indirectly   required by other dependencies. By isolating the high-level dependencies, you   maintain a clear distinction between the essential packages and the ones brought   in transitively.</p> </li> <li> <p><code>requirements-freeze.txt</code>: This file includes all the transitive dependencies   required by the high-level dependencies. It ensures that all the packages needed   for the project, including their versions, are recorded in a separate file. This   separation allows for a more flexible and controlled approach when updating   transitive dependencies while maintaining the reproducibility of your project.</p> </li> </ul> <p>How to update dependencies</p> <p>When updating dependencies, it is essential to primarily modify the high-level <code>requirements.txt</code> file with the desired versions or new packages. Then, generate an updated <code>requirements-freeze.txt</code> file to capture the updated transitive dependencies accurately.</p> <p>Conclusion</p> <p>Prioritizing stability and reproducibility in your project's dependency management is crucial for minimizing compatibility issues, avoiding unexpected bugs, and ensuring a smooth and reliable development process.</p> <p>By using separate requirements files for high-level and transitive dependencies, you gain better visibility and control over the dependencies required by your project. This approach promotes a stable and reproducible development environment while allowing you to update specific packages and their versions when needed. By following these practices, you can ensure the long-term success of your Python projects.</p> Execute the following command(s) in a terminal<pre><code># Freeze the dependencies\npip freeze --local --all &gt; requirements-freeze.txt\n</code></pre> <ul> <li>The <code>--local</code> flag ensures that if a virtualenv has global access, it will not   output globally-installed packages.</li> <li>The <code>--all</code> flag ensures that it does not skip these packages in the output:   <code>setuptools</code>, <code>wheel</code>, <code>pip</code>, <code>distribute</code>.</li> </ul>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#split-the-jupyter-notebook-into-scripts","title":"Split the Jupyter Notebook into scripts","text":"<p>You will split the Jupyter Notebook in a codebase made of separate Python scripts with well defined role. These scripts will be able to be called on the command line, making it ideal for automation tasks.</p> <p>The following table describes the files that you will create in this codebase:</p> File Description Input Output <code>params.yaml</code> The parameters to run the ML experiment - - <code>src/prepare.py</code> Prepare the dataset to run the ML experiment The dataset to prepare in <code>data/raw</code> directory The prepared data in <code>data/prepared</code> directory <code>src/train.py</code> Train the ML model The prepared dataset The model trained with the dataset <code>src/evaluate.py</code> Evaluate the ML model using scikit-learn The model to evaluate The results of the model evaluation in <code>evaluation</code> directory <code>src/utils/seed.py</code> Util function to fix the seed - -"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#move-the-parameters-to-its-own-file","title":"Move the parameters to its own file","text":"<p>Let's split the parameters to run the ML experiment with in a distinct file:</p> params.yaml<pre><code>prepare:\n  seed: 77\n  split: 0.2\n  image_size: [32, 32]\n  grayscale: True\n\ntrain:\n  seed: 77\n  lr: 0.0001\n  epochs: 5\n  conv_size: 32\n  dense_size: 64\n  output_classes: 11\n</code></pre>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#move-the-preparation-step-to-its-own-file","title":"Move the preparation step to its own file","text":"<p>The <code>src/prepare.py</code> script will prepare the dataset. Let's take this opportunity to refactor the code to make it more modular and explicit using functions:</p> src/prepare.py<pre><code>import json\nimport sys\nfrom pathlib import Path\nfrom typing import List\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport yaml\n\nfrom utils.seed import set_seed\n\n\ndef get_preview_plot(ds: tf.data.Dataset, labels: List[str]) -&gt; plt.Figure:\n    \"\"\"Plot a preview of the prepared dataset\"\"\"\n    fig = plt.figure(figsize=(10, 5), tight_layout=True)\n    for images, label_idxs in ds.take(1):\n        for i in range(10):\n            plt.subplot(2, 5, i + 1)\n            plt.imshow(images[i].numpy().astype(\"uint8\"), cmap=\"gray\")\n            plt.title(labels[label_idxs[i].numpy()])\n            plt.axis(\"off\")\n\n    return fig\n\n\ndef main() -&gt; None:\n    if len(sys.argv) != 3:\n        print(\"Arguments error. Usage:\\n\")\n        print(\"\\tpython3 prepare.py &lt;raw-dataset-folder&gt; &lt;prepared-dataset-folder&gt;\\n\")\n        exit(1)\n\n    # Load parameters\n    prepare_params = yaml.safe_load(open(\"params.yaml\"))[\"prepare\"]\n\n    raw_dataset_folder = Path(sys.argv[1])\n    prepared_dataset_folder = Path(sys.argv[2])\n    seed = prepare_params[\"seed\"]\n    split = prepare_params[\"split\"]\n    image_size = prepare_params[\"image_size\"]\n    grayscale = prepare_params[\"grayscale\"]\n\n    # Set seed for reproducibility\n    set_seed(seed)\n\n    # Read data\n    ds_train, ds_test = tf.keras.utils.image_dataset_from_directory(\n        raw_dataset_folder,\n        labels=\"inferred\",\n        label_mode=\"int\",\n        color_mode=\"grayscale\" if grayscale else \"rgb\",\n        batch_size=32,\n        image_size=image_size,\n        shuffle=True,\n        seed=seed,\n        validation_split=split,\n        subset=\"both\",\n    )\n    labels = ds_train.class_names\n\n    if not prepared_dataset_folder.exists():\n        prepared_dataset_folder.mkdir(parents=True)\n\n    # Save the preview plot\n    preview_plot = get_preview_plot(ds_train, labels)\n    preview_plot.savefig(prepared_dataset_folder / \"preview.png\")\n\n    # Normalize the data\n    normalization_layer = tf.keras.layers.Rescaling(\n        1.0 / 255\n    )\n    ds_train = ds_train.map(lambda x, y: (normalization_layer(x), y))\n    ds_test = ds_test.map(lambda x, y: (normalization_layer(x), y))\n\n    # Save the prepared dataset\n    with open(prepared_dataset_folder / \"labels.json\", \"w\") as f:\n        json.dump(labels, f)\n    tf.data.Dataset.save(ds_train, str(prepared_dataset_folder / \"train\"))\n    tf.data.Dataset.save(ds_test, str(prepared_dataset_folder / \"test\"))\n\n    print(f\"\\nDataset saved at {prepared_dataset_folder.absolute()}\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#move-the-train-step-to-its-own-file","title":"Move the train step to its own file","text":"<p>The <code>src/train.py</code> script will train the ML model. Let's take this opportunity to refactor the code to make it more modular and explicit using functions:</p> src/train.py<pre><code>import sys\nfrom pathlib import Path\nfrom typing import Tuple\n\nimport numpy as np\nimport tensorflow as tf\nimport yaml\n\nfrom utils.seed import set_seed\n\n\ndef get_model(\n    image_shape: Tuple[int, int, int],\n    conv_size: int,\n    dense_size: int,\n    output_classes: int,\n) -&gt; tf.keras.Model:\n    \"\"\"Create a simple CNN model\"\"\"\n    model = tf.keras.models.Sequential(\n        [\n            tf.keras.layers.Conv2D(\n                conv_size, (3, 3), activation=\"relu\", input_shape=image_shape\n            ),\n            tf.keras.layers.MaxPooling2D((3, 3)),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(dense_size, activation=\"relu\"),\n            tf.keras.layers.Dense(output_classes),\n        ]\n    )\n    return model\n\n\ndef main() -&gt; None:\n    if len(sys.argv) != 3:\n        print(\"Arguments error. Usage:\\n\")\n        print(\"\\tpython3 train.py &lt;prepared-dataset-folder&gt; &lt;model-folder&gt;\\n\")\n        exit(1)\n\n    # Load parameters\n    prepare_params = yaml.safe_load(open(\"params.yaml\"))[\"prepare\"]\n    train_params = yaml.safe_load(open(\"params.yaml\"))[\"train\"]\n\n    prepared_dataset_folder = Path(sys.argv[1])\n    model_folder = Path(sys.argv[2])\n\n    image_size = prepare_params[\"image_size\"]\n    grayscale = prepare_params[\"grayscale\"]\n    image_shape = (*image_size, 1 if grayscale else 3)\n\n    seed = train_params[\"seed\"]\n    lr = train_params[\"lr\"]\n    epochs = train_params[\"epochs\"]\n    conv_size = train_params[\"conv_size\"]\n    dense_size = train_params[\"dense_size\"]\n    output_classes = train_params[\"output_classes\"]\n\n    # Set seed for reproducibility\n    set_seed(seed)\n\n    # Load data\n    ds_train = tf.data.Dataset.load(str(prepared_dataset_folder / \"train\"))\n    ds_test = tf.data.Dataset.load(str(prepared_dataset_folder / \"test\"))\n\n    # Define the model\n    model = get_model(image_shape, conv_size, dense_size, output_classes)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(lr),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n    )\n    model.summary()\n\n    # Train the model\n    model.fit(\n        ds_train,\n        epochs=epochs,\n        validation_data=ds_test,\n    )\n\n    # Save the model\n    model_folder.mkdir(parents=True, exist_ok=True)\n    model_path = model_folder / \"model.keras\"\n    model.save(model_path)\n    # Save the model history\n    np.save(model_folder / \"history.npy\", model.history.history)\n\n    print(f\"\\nModel saved at {model_folder.absolute()}\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#move-the-evaluate-step-to-its-own-file","title":"Move the evaluate step to its own file","text":"<p>The <code>src/evaluate.py</code> script will evaluate the ML model using DVC. Let's take this opportunity to refactor the code to make it more modular and explicit using functions:</p> src/evaluate.py<pre><code>import json\nimport sys\nfrom pathlib import Path\nfrom typing import List\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\n\ndef get_training_plot(model_history: dict) -&gt; plt.Figure:\n    \"\"\"Plot the training and validation loss\"\"\"\n    epochs = range(1, len(model_history[\"loss\"]) + 1)\n\n    fig = plt.figure(figsize=(10, 4))\n    plt.plot(epochs, model_history[\"loss\"], label=\"Training loss\")\n    plt.plot(epochs, model_history[\"val_loss\"], label=\"Validation loss\")\n    plt.xticks(epochs)\n    plt.title(\"Training and validation loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.grid(True)\n\n    return fig\n\n\ndef get_pred_preview_plot(\n    model: tf.keras.Model, ds_test: tf.data.Dataset, labels: List[str]\n) -&gt; plt.Figure:\n    \"\"\"Plot a preview of the predictions\"\"\"\n    fig = plt.figure(figsize=(10, 5), tight_layout=True)\n    for images, label_idxs in ds_test.take(1):\n        preds = model.predict(images)\n        for i in range(10):\n            plt.subplot(2, 5, i + 1)\n            img = (images[i].numpy() * 255).astype(\"uint8\")\n            # Convert image to rgb if grayscale\n            if img.shape[-1] == 1:\n                img = np.squeeze(img, axis=-1)\n                img = np.stack((img,) * 3, axis=-1)\n            true_label = labels[label_idxs[i].numpy()]\n            pred_label = labels[np.argmax(preds[i])]\n            # Add red border if the prediction is wrong else add green border\n            img = np.pad(img, pad_width=((1, 1), (1, 1), (0, 0)))\n            if true_label != pred_label:\n                img[0, :, 0] = 255  # Top border\n                img[-1, :, 0] = 255  # Bottom border\n                img[:, 0, 0] = 255  # Left border\n                img[:, -1, 0] = 255  # Right border\n            else:\n                img[0, :, 1] = 255\n                img[-1, :, 1] = 255\n                img[:, 0, 1] = 255\n                img[:, -1, 1] = 255\n\n            plt.imshow(img)\n            plt.title(f\"True: {true_label}\\n\" f\"Pred: {pred_label}\")\n            plt.axis(\"off\")\n\n    return fig\n\n\ndef get_confusion_matrix_plot(\n    model: tf.keras.Model, ds_test: tf.data.Dataset, labels: List[str]\n) -&gt; plt.Figure:\n    \"\"\"Plot the confusion matrix\"\"\"\n    fig = plt.figure(figsize=(6, 6), tight_layout=True)\n    preds = model.predict(ds_test)\n\n    conf_matrix = tf.math.confusion_matrix(\n        labels=tf.concat([y for _, y in ds_test], axis=0),\n        predictions=tf.argmax(preds, axis=1),\n        num_classes=len(labels),\n    )\n\n    # Plot the confusion matrix\n    conf_matrix = conf_matrix / tf.reduce_sum(conf_matrix, axis=1)\n    plt.imshow(conf_matrix, cmap=\"Blues\")\n\n    # Plot cell values\n    for i in range(len(labels)):\n        for j in range(len(labels)):\n            value = conf_matrix[i, j].numpy()\n            if value == 0:\n                color = \"lightgray\"\n            elif value &gt; 0.5:\n                color = \"white\"\n            else:\n                color = \"black\"\n            plt.text(\n                j,\n                i,\n                f\"{value:.2f}\",\n                ha=\"center\",\n                va=\"center\",\n                color=color,\n                fontsize=8,\n            )\n\n    plt.colorbar()\n    plt.xticks(range(len(labels)), labels, rotation=90)\n    plt.yticks(range(len(labels)), labels)\n    plt.xlabel(\"Predicted label\")\n    plt.ylabel(\"True label\")\n    plt.title(\"Confusion matrix\")\n\n    return fig\n\n\ndef main() -&gt; None:\n    if len(sys.argv) != 3:\n        print(\"Arguments error. Usage:\\n\")\n        print(\"\\tpython3 evaluate.py &lt;model-folder&gt; &lt;prepared-dataset-folder&gt;\\n\")\n        exit(1)\n\n    model_folder = Path(sys.argv[1])\n    prepared_dataset_folder = Path(sys.argv[2])\n    evaluation_folder = Path(\"evaluation\")\n    plots_folder = Path(\"plots\")\n\n    # Create folders\n    (evaluation_folder / plots_folder).mkdir(parents=True, exist_ok=True)\n\n    # Load files\n    ds_test = tf.data.Dataset.load(str(prepared_dataset_folder / \"test\"))\n    labels = None\n    with open(prepared_dataset_folder / \"labels.json\") as f:\n        labels = json.load(f)\n\n    # Load model\n    model_path = model_folder / \"model.keras\"\n    model = tf.keras.models.load_model(model_path)\n    model_history = np.load(model_folder / \"history.npy\", allow_pickle=True).item()\n\n    # Log metrics\n    val_loss, val_acc = model.evaluate(ds_test)\n    print(f\"Validation loss: {val_loss:.2f}\")\n    print(f\"Validation accuracy: {val_acc * 100:.2f}%\")\n    with open(evaluation_folder / \"metrics.json\", \"w\") as f:\n        json.dump({\"val_loss\": val_loss, \"val_acc\": val_acc}, f)\n\n    # Save training history plot\n    fig = get_training_plot(model_history)\n    fig.savefig(evaluation_folder / plots_folder / \"training_history.png\")\n\n    # Save predictions preview plot\n    fig = get_pred_preview_plot(model, ds_test, labels)\n    fig.savefig(evaluation_folder / plots_folder / \"pred_preview.png\")\n\n    # Save confusion matrix plot\n    fig = get_confusion_matrix_plot(model, ds_test, labels)\n    fig.savefig(evaluation_folder / plots_folder / \"confusion_matrix.png\")\n\n    print(\n        f\"\\nEvaluation metrics and plot files saved at {evaluation_folder.absolute()}\"\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#create-the-seed-helper-function","title":"Create the seed helper function","text":"<p>Finally, add a module for utils:</p> Execute the following command(s) in a terminal<pre><code># Create the utils module\nmkdir src/utils\n\n# Create the __init__.py file to make the utils module a package\ntouch src/utils/__init__.py\n</code></pre> <p>In this module, include <code>src/utils/seed.py</code> to handle the fixing of the seed parameters. This ensure the results are reproducible:</p> src/utils/seed.py<pre><code>import os\nimport random\n\nimport numpy as np\nimport tensorflow as tf\n\n\ndef set_seed(seed: int) -&gt; None:\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n\n    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n\n    tf.random.set_seed(seed)\n    tf.config.threading.set_inter_op_parallelism_threads(1)\n    tf.config.threading.set_intra_op_parallelism_threads(1)\n</code></pre>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#create-a-readmemd-file","title":"Create a <code>README.md</code> file","text":"<p>Finally, create a <code>README.md</code> file at the root of the project to describe the repository. Feel free to use the following template. As you progress though this guide, you can add your notes in the <code>## Notes</code> section:</p> README.md<pre><code># MLOps - Celestial Body Classification\n\nThis repository contains the code from\n[A guide to MLOps](https://mlops.swiss-ai-center.ch/).\n\n## Notes\n&lt;!-- Enter your notes below --&gt;\n</code></pre>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#check-the-results","title":"Check the results","text":"<p>Your working directory should now look like this:</p> <pre><code>.\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 raw\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 src # (1)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 utils\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 seed.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 evaluate.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 prepare.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 train.py\n\u251c\u2500\u2500 README.md # (2)!\n\u251c\u2500\u2500 params.yaml # (3)!\n\u251c\u2500\u2500 requirements-freeze.txt # (4)!\n\u2514\u2500\u2500 requirements.txt # (5)!\n</code></pre> <ol> <li>This, and all its sub-directory, is new.</li> <li>This is new.</li> <li>This is new.</li> <li>This is new.</li> <li>This is new.</li> </ol>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#run-the-experiment","title":"Run the experiment","text":"<p>Awesome! You now have everything you need to run the experiment: the codebase and the dataset are in place, the new virtual environment is set up, and you are ready to run the experiment using scripts for the first time.</p> <p>You can now follow these steps to reproduce the experiment:</p> Execute the following command(s) in a terminal<pre><code># Prepare the dataset\npython3.12 src/prepare.py data/raw data/prepared\n\n# Train the model with the train dataset and save it\npython3.12 src/train.py data/prepared model\n\n# Evaluate the model performance\npython3.12 src/evaluate.py model data/prepared\n</code></pre> <p>The experiment will take some time to run. Once it is done, you will find the results in the <code>data/prepared</code>, <code>model</code>, and <code>evaluation</code> directories.</p>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#check-the-results_1","title":"Check the results","text":"<p>Your working directory should now be similar to this:</p> <pre><code>.\n\u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 prepared # (1)!\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 test\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0  \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 train\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0  \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 labels.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 preview.png\n\u2502   \u251c\u2500\u2500 raw\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u251c\u2500\u2500 evaluation # (2)!\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 plots\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 confusion_matrix.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 pred_preview.png\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 training_history.png\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 metrics.json\n\u251c\u2500\u2500 model # (4)!\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 utils\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u2514\u2500\u2500 seed.py\n\u2502   \u251c\u2500\u2500 evaluate.py\n\u2502   \u251c\u2500\u2500 prepare.py\n\u2502   \u2514\u2500\u2500 train.py\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 params.yaml\n\u251c\u2500\u2500 requirements-freeze.txt\n\u2514\u2500\u2500 requirements.txt\n</code></pre> <ol> <li>This, and all its sub-directory, is new.</li> <li>This, and all its sub-directory, is new.</li> <li>This is new.</li> <li>This is new.</li> </ol> <p>Here, the following should be noted:</p> <ul> <li>the <code>prepare.py</code> script created the <code>data/prepared</code> directory and divided the   dataset into a training set and a test set</li> <li>the <code>train.py</code> script created the <code>model</code> directory and trained the model with   the prepared data.</li> <li>the <code>evaluate.py</code> script created the <code>evaluation</code> directory and generated some   plots and metrics to evaluate the model</li> </ul> <p>Take some time to get familiar with the scripts and the results.</p>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#summary","title":"Summary","text":"<p>Congratulations! You have successfully reproduced the experiment on your machine, this time using a modular approach that can be put into production.</p> <p>In this chapter, you have:</p> <ol> <li>Set up a Python environment using <code>pip</code> and <code>virtualenv</code></li> <li>Adapted the content of the Jupyter Notebook into Python scripts</li> <li>Launched the experiment locally</li> </ol> <p>However, you may have identified the following areas for improvement:</p> <ul> <li> Codebase is not versioned</li> <li> Dataset still needs manual download and placement</li> <li> Steps to run the experiment were not documented</li> <li> Codebase is not easily sharable</li> <li> Dataset is not easily sharable</li> </ul> <p>In the next chapters, you will enhance the workflow to fix those issues.</p> <p>You can now safely continue to the next chapter.</p>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#state-of-the-mlops-process","title":"State of the MLOps process","text":"<ul> <li> Notebook has been transformed into scripts for production</li> <li> Codebase and dataset are not versioned</li> <li> Model steps rely on verbal communication and may be undocumented</li> <li> Changes to model are not easily visualized</li> <li> Model may have required artifacts that are forgotten or omitted in       saved/loaded state</li> <li> Model cannot be easily used from outside of the experiment context</li> </ul> <p>You will address these issues in the next chapters for improved efficiency and collaboration. Continue the guide to learn how.</p>"},{"location":"part-1-local-training/chapter-12-adapt-and-move-the-jupyter-notebook-to-python-scripts/#sources","title":"Sources","text":"<p>Highly inspired by:</p> <ul> <li>Get Started: Data Pipelines - dvc.org</li> <li>How to get stable results with TensorFlow, setting random seed - stackoverflow.com</li> </ul>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/","title":"Chapter 1.3 - Initialize Git and DVC for local training","text":""},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#introduction","title":"Introduction","text":"<p>Now that you have a good understanding of the experiment, it's time to improve the code and data sharing process. To share the codebase, you will create a  Git repository.</p> <p>However, when it comes to managing large files, Git has some limitations. Although Git LFS is an option for handling large files in Git repositories, it may not be the most efficient solution.</p> <p>This is the reason you will use  DVC, a version control system specifically designed to share the data and integrates well with Git. DVC utilizes chunking to efficiently store large files and track their changes.</p> <p>In this chapter, you will learn how to:</p> <ol> <li>Set up a new Git repository</li> <li>Initialize Git in your project directory</li> <li>Verify Git tracking for your files</li> <li>Exclude experiment results, data, models and Python environment files from    Git commits</li> <li>Commit your changes to the Git repository</li> <li>Install DVC</li> <li>Initialize and configure DVC</li> <li>Update the gitignore file and add the experiment data to DVC</li> <li>Push the data files to DVC</li> <li>Commit the metadata files to Git</li> </ol> <p>The following diagram illustrates the control flow of the experiment at the end of this chapter:</p> <pre><code>flowchart TB\n    dot_dvc[(.dvc)]\n    dot_git[(.git)]\n    data[data/raw] &lt;-.-&gt; dot_dvc\n    workspaceGraph &lt;-....-&gt; dot_git\n    subgraph cacheGraph[CACHE]\n        dot_dvc\n        dot_git\n    end\n    subgraph workspaceGraph[WORKSPACE]\n        data --&gt; prepare\n        prepare[prepare.py] --&gt; train\n        train[train.py] --&gt; evaluate[evaluate.py]\n        params[params.yaml] -.- prepare\n        params -.- train\n    end\n    style workspaceGraph opacity:0.4,color:#7f7f7f80\n    style prepare opacity:0.4,color:#7f7f7f80\n    style train opacity:0.4,color:#7f7f7f80\n    style evaluate opacity:0.4,color:#7f7f7f80\n    style params opacity:0.4,color:#7f7f7f80\n    linkStyle 2 opacity:0.4,color:#7f7f7f80\n    linkStyle 3 opacity:0.4,color:#7f7f7f80\n    linkStyle 4 opacity:0.4,color:#7f7f7f80\n    linkStyle 5 opacity:0.4,color:#7f7f7f80\n    linkStyle 6 opacity:0.4,color:#7f7f7f80</code></pre> <p>In future chapters, you will improve the code sharing process by setting up remote Git and DVC repositories to enable easy collaboration with the rest of the team.</p>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#steps","title":"Steps","text":""},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#create-a-new-git-repository","title":"Create a new Git repository","text":""},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#initialize-git-in-your-working-directory","title":"Initialize Git in your working directory","text":"<p>Use the following command to set up a local Git repository in your working directory:</p> Execute the following command(s) in a terminal<pre><code># Initialize Git in your working directory with `main` as the initial branch\ngit init --initial-branch=main\n</code></pre>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#check-if-git-tracks-your-files","title":"Check if Git tracks your files","text":"<p>Initialize Git in your working directory. Verify available files for committing with this command:</p> Execute the following command(s) in a terminal<pre><code># Check the changes\ngit status\n</code></pre> <p>The output should be similar to this:</p> <pre><code>On branch main\n\nNo commits yet\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    .venv/\n    README.md\n    data/\n    evaluation/\n    model/\n    params.yaml\n    requirements-freeze.txt\n    requirements.txt\n    src/\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n</code></pre> <p>As you can see, no files have been added to Git yet.</p>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#create-a-gitignore-file","title":"Create a .gitignore file","text":"<p>Create a <code>.gitignore</code> file to exclude data, models, and Python environment to improve repository size and clone time. The data and models will be managed by DVC in the next chapters. Keep the model's evaluation as it doesn't take much space and you can have a history of the improvements made to your model. Additionally, this will help to ensure that the repository size and clone time remain optimized:</p> .gitignore<pre><code># Data used to train the models\ndata/\n\n# Evaluation results\nevaluation/\n\n# The models\nmodel/\n\n## Python\n.venv/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n</code></pre> <p>Info</p> <p>If using macOS, you might want to ignore <code>.DS_Store</code> files as well to avoid pushing Apple's metadata files to your repository.</p>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#check-the-changes","title":"Check the changes","text":"<p>Check the changes with Git to ensure all wanted files are here with the following commands:</p> Execute the following command(s) in a terminal<pre><code># Add all the available files\ngit add .\n\n# Check the changes\ngit status\n</code></pre> <p>The output of the <code>git status</code> command should be similar to this:</p> <pre><code>On branch main\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n    new file:   .gitignore\n    new file:   README.md\n    new file:   params.yaml\n    new file:   requirements-freeze.txt\n    new file:   requirements.txt\n    new file:   src/evaluate.py\n    new file:   src/prepare.py\n    new file:   src/train.py\n    new file:   src/utils/__init__.py\n    new file:   src/utils/seed.py\n</code></pre>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#commit-the-changes","title":"Commit the changes","text":"<p>Commit the changes to Git:</p> Execute the following command(s) in a terminal<pre><code># Commit the changes\ngit commit -m \"Use Git to version my ML experiment\"\n</code></pre>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#create-a-dvc-repository","title":"Create a DVC repository","text":""},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#install-dvc","title":"Install DVC","text":"<p>Add the main <code>dvc</code> dependency to the <code>requirements.txt</code> file:</p> requirements.txt<pre><code>tensorflow==2.17.1\nmatplotlib==3.9.3\npyyaml==6.0.2\ndvc==3.58.0\n</code></pre> <p>Check the differences with Git to validate the changes:</p> Execute the following command(s) in a terminal<pre><code># Show the differences with Git\ngit diff requirements.txt\n</code></pre> <p>The output should be similar to this:</p> <pre><code>diff --git a/requirements.txt b/requirements.txt\nindex 250f32c..152b868 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -1,3 +1,4 @@\n tensorflow==2.17.1\n matplotlib==3.9.3\n pyyaml==6.0.2\n+dvc==3.58.0\n</code></pre> <p>Install the dependencies and update the freeze file:</p> <p>Warning</p> <p>Prior to running any pip commands, it is crucial to ensure the virtual environment is activated to avoid potential conflicts with system-wide Python packages.</p> <p>To check its status, simply run <code>pip -V</code>. If the virtual environment is active, the output will show the path to the virtual environment's Python executable. If it is not, you can activate it with <code>source .venv/bin/activate</code>.</p> Execute the following command(s) in a terminal<pre><code># Install the dependencies\npip install --requirement requirements.txt\n\n# Freeze the dependencies\npip freeze --local --all &gt; requirements-freeze.txt\n</code></pre>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#initialize-dvc","title":"Initialize DVC","text":"<p>Initialize DVC in the current project.</p> Execute the following command(s) in a terminal<pre><code># Initialize DVC in the working directory\ndvc init\n</code></pre> <p>The <code>dvc init</code> command creates a <code>.dvc</code> directory in the working directory, which serves as the configuration directory for DVC.</p>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#update-the-gitignore-file-and-add-the-experiment-data-to-dvc","title":"Update the .gitignore file and add the experiment data to DVC","text":"<p>With DVC now set up, you can begin adding files to it.</p> <p>Try to add the experiment data. Spoiler, it will fail:</p> Execute the following command(s) in a terminal<pre><code># Try to add the experiment data to DVC\ndvc add data/raw/\n</code></pre> <p>When executing this command, the following output occurs:</p> <pre><code>ERROR: bad DVC file name 'data/data.raw.dvc' is git-ignored.\n</code></pre> <p>You will have to update the gitignore file so that DVC can create files in the <code>data</code> directory. However, you still don't want the directories <code>data/raw</code> and <code>data/prepared</code> to be added to Git.</p> <p>Update the gitignore file by changing <code>data/</code> to <code>data/raw/</code> and <code>data/prepared/</code>:</p> .gitignore<pre><code># Data used to train the models\ndata/raw/\ndata/prepared/\n\n# Evaluation results\nevaluation/\n\n# The models\nmodel/\n\n## Python\n.venv/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n</code></pre> <p>Info</p> <p>If using macOS, you might want to ignore <code>.DS_Store</code> files as well to avoid pushing Apple's metadata files to your repository.</p> <p>Check the differences with Git to validate the changes:</p> Execute the following command(s) in a terminal<pre><code># Show the differences with Git\ngit diff .gitignore\n</code></pre> <p>The output should be similar to this:</p> <pre><code>diff --git a/.gitignore b/.gitignore\nindex dc17ed7..1c13140 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,5 +1,6 @@\n # Data used to train the models\n-data/\n+data/raw/\n+data/prepared/\n\n # Evaluation results\n evaluation/\n</code></pre> <p>You can now add the experiment data to DVC without complain:</p> Execute the following command(s) in a terminal<pre><code># Add the experiment data to DVC\ndvc add data/raw/\n</code></pre> <p>The output should be similar to this. You can safely ignore the message:</p> <pre><code>To track the changes with git, run:\n\n    git add data/raw.dvc data/.gitignore\n\nTo enable auto staging, run:\n\n    dvc config core.autostage true\n</code></pre> <p>The effect of the <code>dvc add</code> command is to create a <code>data/data.raw.dvc</code> file and a <code>data/.gitignore</code>. The <code>.dvc</code> file contains the metadata of the file that is used by DVC to download and check the integrity of the files. The gitignore file is created to add the files in <code>data/raw</code> to be ignored by Git. The <code>.dvc</code> files must be added to Git.</p> <p>Various DVC commands will automatically try to update the gitignore files. If a gitignore file is already present, it will be updated to include the newly ignored files. You might need to update existing <code>.gitignore</code> files accordingly.</p>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#check-the-changes_1","title":"Check the changes","text":"<p>Check the changes with Git to ensure all wanted files are here.</p> Execute the following command(s) in a terminal<pre><code># Add all the files\ngit add .\n\n# Check the changes\ngit status\n</code></pre> <p>The output of the <code>git status</code> command should be similar to this.</p> <pre><code>On branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n    new file:   .dvc/.gitignore\n    new file:   .dvc/config\n    new file:   .dvcignore\n    modified:   .gitignore\n    new file:   data/.gitignore\n    new file:   data/README.md\n    new file:   data/raw.dvc\n    modified:   requirements-freeze.txt\n    modified:   requirements.txt\n</code></pre>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#commit-the-changes-to-git","title":"Commit the changes to Git","text":"<p>You can now commit the changes to Git so the data from DVC is tracked along code changes as well.</p> Execute the following command(s) in a terminal<pre><code># Commit the changes\ngit commit -m \"Use DVC to version the data in my ML experiment\"\n</code></pre> <p>This chapter is done, you can check the summary.</p>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#summary","title":"Summary","text":"<p>Congratulations! You now have a codebase and a dataset that is versioned with Git and DVC. At the moment, these tools are only used locally. In the next chapters, you will learn how to share the codebase and the dataset with the rest of the team.</p> <p>In this chapter, you have successfully:</p> <ol> <li>Set up a new Git repository</li> <li>Initialized Git in your project directory</li> <li>Verified Git tracking for your files</li> <li>Excluded experiment results, data, models and Python environment files from    Git commits</li> <li>Commited your changes to the Git repository</li> <li>Installed DVC</li> <li>Initialized DVC</li> <li>Updated the gitignore file and adding the experiment data to DVC</li> <li>Commited the data files to DVC</li> <li>Commited your changes to the Git repository</li> </ol> <p>You fixed some of the previous issues:</p> <ul> <li> Data no longer needs manual download and is placed in the right directory.</li> <li> Codebase is versioned</li> </ul> <p>You can now safely continue to the next chapter.</p>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#state-of-the-mlops-process","title":"State of the MLOps process","text":"<ul> <li> Notebook has been transformed into scripts for production</li> <li> Codebase and dataset are versioned</li> <li> Model steps rely on verbal communication and may be undocumented</li> <li> Changes to model are not easily visualized</li> <li> Model may have required artifacts that are forgotten or omitted in       saved/loaded state</li> <li> Model cannot be easily used from outside of the experiment context</li> </ul> <p>You will address these issues in the next chapters for improved efficiency and collaboration. Continue the guide to learn how.</p>"},{"location":"part-1-local-training/chapter-13-initialize-git-and-dvc-for-local-training/#sources","title":"Sources","text":"<p>Highly inspired by:</p> <ul> <li>Get Started - dvc.org</li> <li>Get Started: Data Versioning - dvc.org</li> </ul>"},{"location":"part-1-local-training/conclusion/","title":"Conclusion","text":"<p>Congratulations! You did it!</p> <p>In this first part, you were able to run a simple ML experiment with Jupyter Notebook, adapt and move the Jupyter Notebook to Python scripts, and initialize Git and DVC for local training.</p> <p>The following diagram illustrates the bricks you set up at the end of this part.</p> <pre><code>flowchart TB\n    dot_dvc[(.dvc)]\n    dot_git[(.git)]\n    data[data/raw] &lt;-.-&gt; dot_dvc\n    workspaceGraph &lt;-....-&gt; dot_git\n    subgraph cacheGraph[CACHE]\n        dot_dvc\n        dot_git\n    end\n    subgraph workspaceGraph[WORKSPACE]\n        prepare[prepare.py] &lt;-.-&gt; dot_dvc\n        train[train.py] &lt;-.-&gt; dot_dvc\n        evaluate[evaluate.py] &lt;-.-&gt; dot_dvc\n        data --&gt; prepare\n        subgraph dvcGraph[\"dvc.yaml (dvc repro)\"]\n            prepare --&gt; train\n            train --&gt; evaluate\n        end\n        params[params.yaml] -.- prepare\n        params -.- train\n        params &lt;-.-&gt; dot_dvc\n    end</code></pre>"},{"location":"part-1-local-training/introduction/","title":"Introduction","text":"<p>Learn how to train a model locally using  DVC.</p>"},{"location":"part-1-local-training/introduction/#environment","title":"Environment","text":"<p>This guide has been written with  macOS and  Linux operating systems in mind. If you use  Windows, you might encounter issues. Please use the Windows Subsystem for Linux (WSL 2) for optimal results.</p>"},{"location":"part-1-local-training/introduction/#requirements","title":"Requirements","text":"<p>The following requirements are necessary to follow this part:</p> <ul> <li>An IDE. We recommend to use    Visual Studio Code   to follow this guide.</li> <li> Python 3.12</li> <li> pip</li> <li> Git</li> <li>wget</li> <li>unzip</li> </ul> Using a virtual environment manager other than vanilla Python (Conda, Anaconda, etc.)? Read this! <p>While Conda, Anaconda and other Python virtual environment managers might be widely used tools for Python dependency management, they do come with certain drawbacks. Despite being designed to simplify the installation of Python and its packages, they can be complex to work with. This irony arises from the fact that they are praised for simplifying processes, yet their usage can be challenging. Additionally, they introduce a variety of failure modes, which can be numerous and intricate.</p> <p>Addressing these failures often requires significant resources and troubleshooting skills, leading to a diminished overall benefit for the average Python user. Consequently, considering these factors, some users may find that the effort and time required to deal with Conda-related issues outweigh the advantages it provides.</p> <p>In the context of this guide, we highly recommend you to follow it using the vanilla Python environment as it has been tested and validated with it. If you still want to use Conda/Anaconda/etc., please be aware that you might encounter issues.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/","title":"Chapter 2.1 - Reproduce the ML experiment with DVC","text":""},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#introduction","title":"Introduction","text":"<p>A key component of  DVC is the concept of \"stages\". Stages are essentially commands that produce a result, whether that be a file or directory. The beauty of DVC is that these stages are executed only when the dependencies they rely on have changed. This way, you don't have to waste time re-running unnecessary steps.</p> <p>By using DVC stages to create a pipeline, you can execute all of your experiment's steps by simply running the <code>dvc repro</code> command. As a result, DVC will only execute stages that must be ran, making it easy to reproduce the experiment and track the effects of changes.</p> <p>In this chapter, you will learn how to:</p> <ol> <li>Remove custom rules from the gitignore file</li> <li>Set up DVC pipeline stages:<ul> <li>Prepare</li> <li>Train</li> <li>Evaluate</li> </ul> </li> <li>Visualize the pipeline</li> <li>Execute the pipeline</li> <li>Commit the changes to Git</li> </ol> <p>The following diagram illustrates the control flow of the experiment at the end of this chapter:</p> <pre><code>flowchart TB\n    dot_dvc[(.dvc)]\n    dot_git[(.git)]\n    data[data/raw] &lt;-.-&gt; dot_dvc\n    workspaceGraph &lt;-....-&gt; dot_git\n    subgraph cacheGraph[CACHE]\n        dot_dvc\n        dot_git\n    end\n    subgraph workspaceGraph[WORKSPACE]\n        prepare[prepare.py] &lt;-.-&gt; dot_dvc\n        train[train.py] &lt;-.-&gt; dot_dvc\n        evaluate[evaluate.py] &lt;-.-&gt; dot_dvc\n        data --&gt; prepare\n        subgraph dvcGraph[\"dvc.yaml (dvc repro)\"]\n            prepare --&gt; train\n            train --&gt; evaluate\n        end\n        params[params.yaml] -.- prepare\n        params -.- train\n        params &lt;-.-&gt; dot_dvc\n    end\n    style dot_git opacity:0.4,color:#7f7f7f80\n    style data opacity:0.4,color:#7f7f7f80\n    linkStyle 0 opacity:0.4,color:#7f7f7f80\n    linkStyle 1 opacity:0.4,color:#7f7f7f80</code></pre> <p>As a reminder, the current steps to run the experiment are as follow:</p> Execute the following command(s) in a terminal<pre><code># Prepare the dataset\npython3.12 src/prepare.py data/raw data/prepared\n\n# Train the model with the train dataset and save it\npython3.12 src/train.py data/prepared model\n\n# Evaluate the model performances\npython3.12 src/evaluate.py model data/prepared\n</code></pre> <p>Let's get started!</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#steps","title":"Steps","text":""},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#remove-custom-rules-from-the-gitignore-file","title":"Remove custom rules from the gitignore file","text":"<p>As seen in the previous chapter, DVC can update gitignore files.</p> <p>As you will define the entire experiment pipeline with DVC, you can safely remove all the custom rules from the main gitignore file so DVC can manage them for you. At the end of this chapter, DVC should have updated all the gitignore files.</p> <p>Replace all the actual content of the gitignore file with the following to remove your experiment data. The required files to be ignored will then be added by DVC:</p> .gitignore<pre><code>## Python\n.venv/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n\n## DVC\n\n# DVC will add new files after this line\n</code></pre> <p>Info</p> <p>If using macOS, you might want to ignore <code>.DS_Store</code> files as well to avoid pushing Apple's metadata files to your repository.</p> <p>Check the differences with Git to validate the changes:</p> Execute the following command(s) in a terminal<pre><code># Show the differences with Git\ngit diff .gitignore\n</code></pre> <p>The output should be similar to this:</p> <pre><code>diff --git a/.gitignore b/.gitignore\nindex 1c13140..2492093 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,15 +1,9 @@\n-# Data used to train the models\n-data/raw/\n-data/prepared/\n-\n-# Evaluation results\n-evaluation/\n-\n-# The models\n-model/\n-\n ## Python\n .venv/\n\n # Byte-compiled / optimized / DLL files\n __pycache__/\n+\n+## DVC\n+\n+# DVC will add new files after this line\n</code></pre>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#setup-the-dvc-pipeline-stages","title":"Setup the DVC pipeline stages","text":"<p>A DVC pipeline is a set of stages that are executed in a specific order based on the dependencies between the stages (deps and outs). The <code>dvc repro</code> command executes the pipeline to reproduce the experiment.</p> <p>In the following sections, each step of the experiment will be converted into a stage of a DVC pipeline. The <code>dvc stage add</code> command creates a new stage in the pipeline. This stage will be added to the <code>dvc.yaml</code> file that describes the pipeline. This file can also be edited manually.</p> <p>The <code>dvc stage add</code> accepts some options:</p> <ul> <li><code>-n</code> specifies the name of the stage</li> <li><code>-p</code> specifies the parameters of the stage (referenced in the <code>params.yaml</code>   file)</li> <li><code>-d</code> specifies the dependencies of the stage</li> <li><code>-o</code> specifies the outputs of the stage (cached by DVC)</li> <li><code>--metrics</code> specifies the metrics of the stage (cached by DVC)</li> <li><code>--plots</code> specifies the plots of the stage (cached by DVC)</li> </ul> <p>As parameters are an important part of the experiment, they are versioned in a <code>params.yaml</code> file. DVC keeps track of these parameters and of the corresponding results.</p> <p>Dependencies and outputs are files or directories that are used or produced by the stage. If any of these files change, DVC will re-run the command of the stage when using <code>dvc repro</code>.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#prepare-stage","title":"Prepare stage","text":"<p>Run the following command to add a new stage called prepare that prepares the dataset:</p> Execute the following command(s) in a terminal<pre><code>dvc stage add -n prepare \\\n    -p prepare \\\n    -d src/prepare.py -d src/utils/seed.py -d data/raw \\\n    -o data/prepared \\\n    python3.12 src/prepare.py data/raw data/prepared\n</code></pre> <p>The values of the parameters is <code>prepare</code> which includes all the <code>prepare</code> parameters referenced in the <code>params.yaml</code> file.</p> <p>This stage has the <code>src/prepare.py</code>, the <code>src/utils/seed.py</code> and <code>data/raw</code> files as dependencies. If any of these files change, DVC will run the command <code>python3.12 src/prepare.py data/raw data/prepared</code> when using <code>dvc repro</code>.</p> <p>The output of this command is stored in the <code>data/prepared</code> directory.</p> <p>Take some time to explore the <code>dvc.yaml</code> file and to understand how the pipeline is updated.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#train-stage","title":"Train stage","text":"<p>Run the following command to create a new stage called train that trains the model:</p> Execute the following command(s) in a terminal<pre><code>dvc stage add -n train \\\n    -p train \\\n    -d src/train.py -d src/utils/seed.py -d data/prepared \\\n    -o model \\\n    python3.12 src/train.py data/prepared model\n</code></pre> <p>The values of the parameters is <code>train</code> which includes all the <code>train</code> parameters referenced in the <code>params.yaml</code> file.</p> <p>This stage has the <code>src/train.py</code>, the <code>src/utils/seed.py</code> and <code>data/prepared</code> files as dependencies. If any of these files change, DVC will run the command <code>python3.12 src/evaluate.py data/prepared model</code> when using <code>dvc repro</code>.</p> <p>The output of this command is stored in the <code>model</code> directory.</p> <p>Explore the <code>dvc.yaml</code> file to understand how the pipeline is updated.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#evaluate-stage","title":"Evaluate stage","text":"<p>Run the following command to create a new stage called evaluate that evaluates the model:</p> Execute the following command(s) in a terminal<pre><code>dvc stage add -n evaluate \\\n    -d src/evaluate.py -d model \\\n    --metrics evaluation/metrics.json \\\n    --plots evaluation/plots/confusion_matrix.png \\\n    --plots evaluation/plots/pred_preview.png \\\n    --plots evaluation/plots/training_history.png \\\n    python3.12 src/evaluate.py model data/prepared\n</code></pre> <p>This stage has the <code>src/evaluate.py</code> file and then <code>model</code> folder as dependencies. If any of these files change, DVC will run the command <code>python3.12 src/evaluate.py model data/prepared</code> when using <code>dvc repro</code>.</p> <p>The script writes the model's metrics to <code>evaluation/metrics.json</code>, the <code>confusion_matrix</code> to <code>evaluation/plots/confusion_matrix.png</code>, the <code>pred_preview</code> to <code>evaluation/plots/pred_preview.png</code> and the <code>training_history.png</code> to <code>evaluation/plots/training_history.png</code>.</p> <p>Explore the <code>dvc.yaml</code> file to understand how the pipeline is updated.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#summary-of-the-dvc-pipeline","title":"Summary of the DVC pipeline","text":"<p>The pipeline is now entirely defined. You can explore the <code>dvc.yaml</code> file to see all the stages and their dependencies.</p> <p>Notice that DVC also updated the main gitignore file with the model, as it is an output of the <code>train</code> stage:</p> .gitignore<pre><code>## Python\n.venv/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n\n## DVC\n\n# DVC will add new files after this line\n/model\n</code></pre> <p>Info</p> <p>If using macOS, you might want to ignore <code>.DS_Store</code> files as well to avoid pushing Apple's metadata files to your repository.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#visualize-the-pipeline","title":"Visualize the pipeline","text":"<p>You can visualize the pipeline to check the stages that will be performed:</p> Execute the following command(s) in a terminal<pre><code># Display the Directed Acyclic Graph of the pipeline\ndvc dag\n</code></pre> <pre><code>+--------------+\n| data/raw.dvc |\n+--------------+\n        *\n        *\n        *\n  +---------+\n  | prepare |\n  +---------+\n        *\n        *\n        *\n    +-------+\n    | train |\n    +-------+\n        *\n        *\n        *\n  +----------+\n  | evaluate |\n  +----------+\n</code></pre> <p>If any dependencies/outputs change, the affected stages will be re-executed.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#execute-the-pipeline","title":"Execute the pipeline","text":"<p>Now that the pipeline has been defined, you can execute it and reproduce the experiment:</p> Execute the following command(s) in a terminal<pre><code># Execute only the required pipeline stages\ndvc repro\n</code></pre> <p>Tip</p> <p>You can force the execution of the entire pipeline with the command <code>dvc repro --force</code>.</p> <p>The first execution will generate a <code>dvc.lock</code> file that contains the information about the pipeline and the outputs of the stages.</p> <p>Try to run the command again and notice that DVC will not re-execute the stages:</p> <pre><code>'data/raw.dvc' didn't change, skipping\nStage 'prepare' didn't change, skipping\nStage 'train' didn't change, skipping\nStage 'evaluate' didn't change, skipping\nData and pipelines are up to date.\n</code></pre>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#check-the-changes","title":"Check the changes","text":"<p>Check the changes with Git to ensure all wanted files are here:</p> Execute the following command(s) in a terminal<pre><code># Add all the files\ngit add .\n\n# Check the changes\ngit status\n</code></pre> <p>The output of the <code>git status</code> command should be similar to this.</p> <pre><code>On branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n    modified:   .gitignore\n    modified:   data/.gitignore\n    new file:   dvc.lock\n    new file:   dvc.yaml\n    new file:   evaluation/.gitignore\n    new file:   evaluation/plots/.gitignore\n</code></pre>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#commit-the-changes","title":"Commit the changes","text":"<p>Commit the changes to the local Git repository:</p> Execute the following command(s) in a terminal<pre><code># Commit the changes\ngit commit -m \"Use DVC to save the commands of my ML experiment\"\n</code></pre> <p>This chapter is done, you can check the summary.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#summary","title":"Summary","text":"<p>Congratulations! You have defined a pipeline and know how to reproduce your experiment.</p> <p>In this chapter, you have successfully:</p> <ol> <li>Removed custom rules from the main gitignore file</li> <li>Set up three DVC pipeline stages<ul> <li>Prepare</li> <li>Train</li> <li>Evaluate</li> </ul> </li> <li>Visualized the pipeline</li> <li>Executed the pipeline</li> <li>Committed the changes</li> </ol> <p>You fixed some of the previous issues:</p> <ul> <li> The steps used to create the model are documented and can be reproduced.</li> </ul> <p>However, you might have identified the following areas for improvement:</p> <ul> <li> How can I ensure my changes helps to improve the model?</li> <li> How can I ensure my model still can be run on someone's computer?</li> </ul> <p>In the next chapters, you will enhance the workflow to fix these issues.</p> <p>You can now safely continue to the next chapter.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#state-of-the-mlops-process","title":"State of the MLOps process","text":"<ul> <li> Notebook has been transformed into scripts for production</li> <li> Codebase and dataset are versioned</li> <li> Steps used to create the model are documented and can be re-executed</li> <li> Changes to model are not easily visualized</li> <li> Model may have required artifacts that are forgotten or omitted in       saved/loaded state</li> <li> Model cannot be easily used from outside of the experiment context</li> </ul> <p>You will address these issues in the next chapters for improved efficiency and collaboration. Continue the guide to learn how.</p>"},{"location":"part-2-model-evaluation/chapter-21-reproduce-the-ml-experiment-with-dvc/#sources","title":"Sources","text":"<p>Highly inspired by:</p> <ul> <li>Get Started: Data Pipelines - dvc.org</li> <li>plots - dvc.org</li> </ul>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/","title":"Chapter 2.2 - Track model evolution with DVC","text":""},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#introduction","title":"Introduction","text":"<p>In the previous chapter, you did set up a  DVC pipeline to reproduce your experiment.</p> <p>Once this stage is created, you will be able to change our model's configuration, evaluate the new configuration and compare its performance with the last committed ones.</p> <p>In this chapter, you will learn how to:</p> <ol> <li>Update the parameters of the experiment</li> <li>Reproduce the experiment</li> <li>Visualize the changes made to the model</li> </ol> <p>Let's get started!</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#steps","title":"Steps","text":""},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#update-the-parameters-of-the-experiment","title":"Update the parameters of the experiment","text":"<p>Update your experiment with the following parameters by editing the <code>params.yaml</code> file:</p> params.yaml<pre><code>prepare:\n  seed: 77\n  split: 0.2\n  image_size: [32, 32]\n  grayscale: True\n\ntrain:\n  seed: 77\n  lr: 0.0001\n  epochs: 10\n  conv_size: 32\n  dense_size: 64\n  output_classes: 11\n</code></pre> <p>Check the differences with Git to validate the changes:</p> Execute the following command(s) in a terminal<pre><code># Show the differences with Git\ngit diff params.yaml\n</code></pre> <p>The output should be similar to this:</p> <pre><code>diff --git a/params.yaml b/params.yaml\nindex 5bb698e..6a6ff45 100644\n--- a/params.yaml\n+++ b/params.yaml\n@@ -7,7 +7,7 @@ prepare:\n train:\n   seed: 77\n   lr: 0.0001\n-  epochs: 5\n+  epochs: 10\n   conv_size: 32\n   dense_size: 64\n   output_classes: 11\n</code></pre> <p>Here, you simply changed the <code>epochs</code> parameter of the Train stage, which should slightly affect the model's performance.</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#reproduce-the-experiment","title":"Reproduce the experiment","text":"<p>Let's discover if these changes are positive or not! To do so, you will need to reproduce the experiment:</p> Execute the following command(s) in a terminal<pre><code># Run the experiment. DVC will automatically run all required stages\ndvc repro\n</code></pre>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#compare-the-two-iterations","title":"Compare the two iterations","text":"<p>You will now use DVC to compare your changes with the last committed ones. For DVC, <code>HEAD</code> refers to the last commit on the branch you are working on (at this moment, the branch <code>main</code>), and <code>workspace</code> refers to the current state of your working directory.</p> <p>Note</p> <p>Remember? You did set the parameters, metrics and plots in the previous chapter: Chapter 2.1: Reproduce the ML experiment with DVC.</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#compare-the-parameters-difference","title":"Compare the parameters difference","text":"<p>In order to compare the parameters, you will need to use the <code>dvc params diff</code>. This command will compare the parameters that were set on <code>HEAD</code> and the ones in your current <code>workspace</code>:</p> Execute the following command(s) in a terminal<pre><code># Compare the parameters' difference\ndvc params diff\n</code></pre> <p>The output should look like this:</p> <pre><code>Path         Param         HEAD    workspace\nparams.yaml  train.epochs  5       10\n</code></pre> <p>DVC displays the differences between <code>HEAD</code> and <code>workspace</code>, so you can easily compare the two iterations.</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#compare-the-metrics-difference","title":"Compare the metrics difference","text":"<p>Similarly, you can use the <code>dvc metrics diff</code> command to compare the metrics that were computed on <code>HEAD</code> and the ones that were computed in your current <code>workspace</code>:</p> Execute the following command(s) in a terminal<pre><code># Compare the metrics' difference\ndvc metrics diff\n</code></pre> <p>The output should look like this:</p> <pre><code>Path                     Metric    HEAD     workspace    Change\nevaluation/metrics.json  val_acc   0.58879  0.74143      0.15265\nevaluation/metrics.json  val_loss  1.89269  1.34434      -0.54835\n</code></pre> <p>Again, DVC shows you the differences, so you can easily compare the two iterations. Here, you can see that the metrics have slightly improved.</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#compare-the-plots-difference","title":"Compare the plots difference","text":"<p>Finally, you can use the <code>dvc plots diff</code> command to compare the plots that were generated on <code>HEAD</code> and the ones that were generated in your current <code>workspace</code>:</p> Execute the following command(s) in a terminal<pre><code># Create the report to display the plots\ndvc plots diff --open\n</code></pre> <p>Tip for WSL2 users</p> <p>When using WSL2, this command will not succeed by default but the report is available by clicking on the <code>dvc_plots/index.html</code> file.</p> <p>The Linux distribution is accessible through the <code>\\\\wsl.localhost\\</code> address in the file explorer. The current directory can also be opened directly from the shell with the <code>explorer.exe .</code> command.</p> <p>Warning</p> <p>Do not enable auto-opening using the suggested command <code>dvc config plots.auto_open true</code>, as this will cause complications in subsequent steps.</p> <p>The effect of the <code>dvc plots diff</code> command is to create a <code>dvc_plots</code> directory in the working directory. This directory contains a report to visualize the plots in a browser.</p> <p>As for the other commands, DVC shows you the differences so you can easily compare the two iterations.</p> <p>Here is a preview of the report:</p> <p></p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#summary-of-the-model-evolutions","title":"Summary of the model evolutions","text":"<p>You should notice the improvements made to the model thanks to the DVC reports. These improvements are small but illustrate the workflow. Try to tweak the parameters to improve the model and play with the reports to see how your model's performance changes.</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#update-the-gitignore-file","title":"Update the .gitignore file","text":"<p>The <code>dvc plots diff</code> creates a <code>dvc_plots</code> directory in the working directory. This directory should be ignored by Git.</p> <p>Add the <code>dvc_plots</code> directory to the gitignore file:</p> .gitignore<pre><code>## Python\n.venv/\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n\n## DVC\n\n# DVC plots\ndvc_plots\n\n# DVC will add new files after this line\n/model\n</code></pre> <p>Info</p> <p>If using macOS, you might want to ignore <code>.DS_Store</code> files as well to avoid pushing Apple's metadata files to your repository.</p> <p>Check the differences with Git to validate the changes:</p> Execute the following command(s) in a terminal<pre><code># Show the differences with Git\ngit diff .gitignore\n</code></pre> <p>The output should be similar to this:</p> <pre><code>diff --git a/.gitignore b/.gitignore\nindex 8a2668e..cbfa93b 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -6,5 +6,8 @@ __pycache__/\n\n ## DVC\n\n+# DVC plots\n+dvc_plots\n+\n # DVC will add new files after this line\n /model\n</code></pre>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#check-the-changes","title":"Check the changes","text":"<p>Check the changes with Git to ensure that all the necessary files are tracked:</p> Execute the following command(s) in a terminal<pre><code># Add all the files\ngit add .\n\n# Check the changes\ngit status\n</code></pre> <p>The output should look like this.</p> <pre><code>On branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   .gitignore\n        modified:   dvc.lock\n        modified:   params.yaml\n</code></pre>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#commit-the-changes","title":"Commit the changes","text":"<p>Commit the changes to the local Git repository:</p> Execute the following command(s) in a terminal<pre><code># Commit the changes\ngit commit -m \"Track changes of my ML experiment\"\n</code></pre> <p>This chapter is done, you can check the summary.</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#summary","title":"Summary","text":"<p>Congratulations! You now have a simple way to compare the two iterations of your experiment.</p> <p>In this chapter, you have successfully:</p> <ol> <li>Updated the experiment parameters</li> <li>Reproduced the experiment</li> <li>Visualized the changes made to the experiment</li> <li>Commited the changes</li> </ol> <p>You fixed some of the previous issues:</p> <ul> <li> The changes done to a model can be visualized with parameters, metrics and       plots to identify differences between iterations</li> </ul> <p>You have solid metrics to evaluate the changes before integrating your work in the code codebase.</p> <p>You can now safely continue to the next chapter.</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#state-of-the-mlops-process","title":"State of the MLOps process","text":"<ul> <li> Notebook has been transformed into scripts for production</li> <li> Codebase and dataset are versioned</li> <li> Steps used to create the model are documented and can be re-executed</li> <li> Changes done to a model can be visualized with parameters, metrics and       plots to identify differences between iterations</li> <li> Model may have required artifacts that are forgotten or omitted in       saved/loaded state</li> <li> Model cannot be easily used from outside of the experiment context</li> </ul> <p>You will address these issues in the next chapters for improved efficiency and collaboration. Continue the guide to learn how.</p>"},{"location":"part-2-model-evaluation/chapter-22-track-model-evolution-with-dvc/#sources","title":"Sources","text":"<p>Highly inspired by:</p> <ul> <li>Get Started: Metrics, Parameters, and Plots - dvc.org</li> </ul>"},{"location":"part-2-model-evaluation/conclusion/","title":"Conclusion","text":"<p>Congratulations! You did it!</p> <p>In this second part, you were able to reproduce the ML experiment with DVC and track model evolution with DVC.</p> <p>The following diagram illustrates the bricks you set up at the end of this part.</p> <pre><code>flowchart TB\n    dot_dvc[(.dvc)]\n    dot_git[(.git)]\n    data[data/raw] &lt;-.-&gt; dot_dvc\n    workspaceGraph &lt;-....-&gt; dot_git\n    subgraph cacheGraph[CACHE]\n        dot_dvc\n        dot_git\n    end\n    subgraph workspaceGraph[WORKSPACE]\n        prepare[prepare.py] &lt;-.-&gt; dot_dvc\n        train[train.py] &lt;-.-&gt; dot_dvc\n        evaluate[evaluate.py] &lt;-.-&gt; dot_dvc\n        data --&gt; prepare\n        subgraph dvcGraph[\"dvc.yaml (dvc repro)\"]\n            prepare --&gt; train\n            train --&gt; evaluate\n        end\n        params[params.yaml] -.- prepare\n        params -.- train\n        params &lt;-.-&gt; dot_dvc\n    end</code></pre>"},{"location":"part-2-model-evaluation/introduction/","title":"Introduction","text":"<p>Learn how to evaluate a model using  DVC.</p>"},{"location":"part-2-model-evaluation/introduction/#environment","title":"Environment","text":"<p>This guide has been written with  macOS and  Linux operating systems in mind. If you use  Windows, you might encounter issues. Please use the Windows Subsystem for Linux (WSL 2) for optimal results.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/","title":"Chapter 3.1 - Save and load the model with BentoML","text":""},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#introduction","title":"Introduction","text":"<p>The purpose of this chapter is to serve and use the model for usage outside of the experiment context with the help of  BentoML, a tool designed for easy packaging, deployment, and serving of Machine Learning models.</p> <p>By transforming your model into a BentoML model artifact, it is possible to load the model for future usage with all its dependencies. This will allow you to use the model in a production environment, share it with others, and deploy it to a cluster.</p> <p>In this chapter, you will learn how to:</p> <ol> <li>Install BentoML</li> <li>Learn about BentoML's model store</li> <li>Update and run the experiment to use BentoML to save and load the model to    and from the model's store</li> </ol> <p>The following diagram illustrates the control flow of the experiment at the end of this chapter:</p> <pre><code>flowchart TB\n    workspaceGraph &lt;-....-&gt; dot_git\n    data[data/raw]\n    subgraph cacheGraph[CACHE]\n        dot_dvc[(.dvc)]\n        dot_git[(.git)]\n    end\n    subgraph workspaceGraph[WORKSPACE]\n        data --&gt; code[*.py]\n        subgraph dvcGraph[\"dvc.yaml\"]\n            code\n        end\n        params[params.yaml] -.- code\n        bento_model[model/classifier.bentomodel]\n        bento_model &lt;-.-&gt; dot_dvc\n        code --&gt; |save_model\n                  export_model|bento_model\n        bento_model --&gt; |import_model\n                         load_model|code\n    end\n    style workspaceGraph opacity:0.4,color:#7f7f7f80\n    style dvcGraph opacity:0.4,color:#7f7f7f80\n    style cacheGraph opacity:0.4,color:#7f7f7f80\n    style data opacity:0.4,color:#7f7f7f80\n    style dot_git opacity:0.4,color:#7f7f7f80\n    style dot_dvc opacity:0.4,color:#7f7f7f80\n    style code opacity:0.4,color:#7f7f7f80\n    style params opacity:0.4,color:#7f7f7f80\n    linkStyle 0 opacity:0.4,color:#7f7f7f80\n    linkStyle 1 opacity:0.4,color:#7f7f7f80\n    linkStyle 2 opacity:0.4,color:#7f7f7f80\n    linkStyle 3 opacity:0.4,color:#7f7f7f80\n    linkStyle 4 opacity:0.4,color:#7f7f7f80\n    linkStyle 5 opacity:0.4,color:#7f7f7f80</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#steps","title":"Steps","text":""},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#install-bentoml-and-dependencies","title":"Install BentoML and dependencies","text":"<p>Add the <code>bentoml</code> package to install BentoML support. <code>pillow</code> is also added to support image processing:</p> requirements.txt<pre><code>tensorflow==2.17.1\nmatplotlib==3.9.3\npyyaml==6.0.2\ndvc==3.58.0\nbentoml==1.3.15\npillow==11.0.0\n</code></pre> <p>Check the differences with Git to validate the changes:</p> Execute the following command(s) in a terminal<pre><code># Show the differences with Git\ngit diff requirements.txt\n</code></pre> <p>The output should be similar to this:</p> <pre><code>diff --git a/requirements.txt b/requirements.txt\nindex 4b8d3d9..d584cca 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -2,3 +2,5 @@ tensorflow==2.17.1\n matplotlib==3.9.3\n pyyaml==6.0.2\n dvc==3.58.0\n+bentoml==1.3.15\n+pillow==11.0.0\n</code></pre> <p>Install the package and update the freeze file.</p> <p>Warning</p> <p>Prior to running any pip commands, it is crucial to ensure the virtual environment is activated to avoid potential conflicts with system-wide Python packages.</p> <p>To check its status, simply run <code>pip -V</code>. If the virtual environment is active, the output will show the path to the virtual environment's Python executable. If it is not, you can activate it with <code>source .venv/bin/activate</code>.</p> Execute the following command(s) in a terminal<pre><code># Install the dependencies\npip install --requirement requirements.txt\n\n# Freeze the dependencies\npip freeze --local --all &gt; requirements-freeze.txt\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#update-the-experiment","title":"Update the experiment","text":"<p>To make the most of BentoML's capabilities, you must start by converting your model into the specialized BentoML model artifact format with all its dependencies.</p> <p>BentoML offers a model store, which is a centralized repository for all your models. This store is stored in a directory on your local machine at <code>~/bentoml/</code>.</p> <p>In order to share the model with others, the model must be exported in the current working directory. It will then be uploaded to DVC and shared with others.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#update-srctrainpy","title":"Update <code>src/train.py</code>","text":"<p>Update the <code>src/train.py</code> file to save the model with BentoML:</p> src/train.py<pre><code>import json\nimport sys\nfrom pathlib import Path\nfrom typing import Tuple\n\nimport numpy as np\nimport tensorflow as tf\nimport yaml\nimport bentoml\nfrom PIL.Image import Image\n\nfrom utils.seed import set_seed\n\n\ndef get_model(\n    image_shape: Tuple[int, int, int],\n    conv_size: int,\n    dense_size: int,\n    output_classes: int,\n) -&gt; tf.keras.Model:\n    \"\"\"Create a simple CNN model\"\"\"\n    model = tf.keras.models.Sequential(\n        [\n            tf.keras.layers.Conv2D(\n                conv_size, (3, 3), activation=\"relu\", input_shape=image_shape\n            ),\n            tf.keras.layers.MaxPooling2D((3, 3)),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(dense_size, activation=\"relu\"),\n            tf.keras.layers.Dense(output_classes),\n        ]\n    )\n    return model\n\n\ndef main() -&gt; None:\n    if len(sys.argv) != 3:\n        print(\"Arguments error. Usage:\\n\")\n        print(\"\\tpython3 train.py &lt;prepared-dataset-folder&gt; &lt;model-folder&gt;\\n\")\n        exit(1)\n\n    # Load parameters\n    prepare_params = yaml.safe_load(open(\"params.yaml\"))[\"prepare\"]\n    train_params = yaml.safe_load(open(\"params.yaml\"))[\"train\"]\n\n    prepared_dataset_folder = Path(sys.argv[1])\n    model_folder = Path(sys.argv[2])\n\n    image_size = prepare_params[\"image_size\"]\n    grayscale = prepare_params[\"grayscale\"]\n    image_shape = (*image_size, 1 if grayscale else 3)\n\n    seed = train_params[\"seed\"]\n    lr = train_params[\"lr\"]\n    epochs = train_params[\"epochs\"]\n    conv_size = train_params[\"conv_size\"]\n    dense_size = train_params[\"dense_size\"]\n    output_classes = train_params[\"output_classes\"]\n\n    # Set seed for reproducibility\n    set_seed(seed)\n\n    # Load data\n    ds_train = tf.data.Dataset.load(str(prepared_dataset_folder / \"train\"))\n    ds_test = tf.data.Dataset.load(str(prepared_dataset_folder / \"test\"))\n\n    labels = None\n    with open(prepared_dataset_folder / \"labels.json\") as f:\n        labels = json.load(f)\n\n    # Define the model\n    model = get_model(image_shape, conv_size, dense_size, output_classes)\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(lr),\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n    )\n    model.summary()\n\n    # Train the model\n    model.fit(\n        ds_train,\n        epochs=epochs,\n        validation_data=ds_test,\n    )\n\n    # Save the model\n    model_folder.mkdir(parents=True, exist_ok=True)\n\n    def preprocess(x: Image):\n        # convert PIL image to tensor\n        x = x.convert('L' if grayscale else 'RGB')\n        x = x.resize(image_size)\n        x = np.array(x)\n        x = x / 255.0\n        # add batch dimension\n        x = np.expand_dims(x, axis=0)\n        return x\n\n    def postprocess(x: Image):\n        return {\n            \"prediction\": labels[tf.argmax(x, axis=-1).numpy()[0]],\n            \"probabilities\": {\n                labels[i]: prob\n                for i, prob in enumerate(tf.nn.softmax(x).numpy()[0].tolist())\n            },\n        }\n\n    # Save the model using BentoML to its model store\n    # https://docs.bentoml.com/en/latest/reference/frameworks/keras.html#bentoml.keras.save_model\n    bentoml.keras.save_model(\n        \"celestial_bodies_classifier_model\",\n        model,\n        include_optimizer=True,\n        custom_objects={\n            \"preprocess\": preprocess,\n            \"postprocess\": postprocess,\n        }\n    )\n\n    # Export the model from the model store to the local model folder\n    bentoml.models.export_model(\n        \"celestial_bodies_classifier_model:latest\",\n        f\"{model_folder}/celestial_bodies_classifier_model.bentomodel\",\n    )\n\n    # Save the model history\n    np.save(model_folder / \"history.npy\", model.history.history)\n\n    print(f\"\\nModel saved at {model_folder.absolute()}\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>BentoML can save the model with custom objects.</p> <p>These custom objects can be used to save the model with arbitrary data that can be used afterword when loading back the model. In this case, the following objects are saved with the model:</p> <ul> <li><code>preprocess</code> is used to preprocess the input data before feeding it to the   model.</li> <li><code>postprocess</code> is used to postprocess the output of the model.</li> </ul> <p>These functions will be used later to transform the input and output data when using the model through a HTTP REST API.</p> <p>Check the differences with Git to better understand the changes:</p> Execute the following command(s) in a terminal<pre><code># Show the differences with Git\ngit diff src/train.py\n</code></pre> <p>The output should be similar to this:</p> <pre><code>diff --git a/src/train.py b/src/train.py\nindex 5c69e2f..b845eb3 100644\n--- a/src/train.py\n+++ b/src/train.py\n@@ -1,3 +1,4 @@\n+import json\n import sys\n from pathlib import Path\n from typing import Tuple\n@@ -5,6 +6,8 @@ from typing import Tuple\n import numpy as np\n import tensorflow as tf\n import yaml\n+import bentoml\n+from PIL.Image import Image\n\n from utils.seed import set_seed\n\n@@ -61,6 +64,10 @@ def main() -&gt; None:\n     ds_train = tf.data.Dataset.load(str(prepared_dataset_folder / \"train\"))\n     ds_test = tf.data.Dataset.load(str(prepared_dataset_folder / \"test\"))\n\n+    labels = None\n+    with open(prepared_dataset_folder / \"labels.json\") as f:\n+        labels = json.load(f)\n+\n     # Define the model\n     model = get_model(image_shape, conv_size, dense_size, output_classes)\n     model.compile(\n@@ -79,8 +86,44 @@ def main() -&gt; None:\n\n     # Save the model\n     model_folder.mkdir(parents=True, exist_ok=True)\n-    model_path = model_folder / \"model.keras\"\n-    model.save(model_path)\n+\n+    def preprocess(x: Image):\n+        # convert PIL image to tensor\n+        x = x.convert('L' if grayscale else 'RGB')\n+        x = x.resize(image_size)\n+        x = np.array(x)\n+        x = x / 255.0\n+        # add batch dimension\n+        x = np.expand_dims(x, axis=0)\n+        return x\n+\n+    def postprocess(x: Image):\n+        return {\n+            \"prediction\": labels[tf.argmax(x, axis=-1).numpy()[0]],\n+            \"probabilities\": {\n+                labels[i]: prob\n+                for i, prob in enumerate(tf.nn.softmax(x).numpy()[0].tolist())\n+            },\n+        }\n+\n+    # Save the model using BentoML to its model store\n+    # https://docs.bentoml.com/en/latest/reference/frameworks/keras.html#bentoml.keras.save_model\n+    bentoml.keras.save_model(\n+        \"celestial_bodies_classifier_model\",\n+        model,\n+        include_optimizer=True,\n+        custom_objects={\n+            \"preprocess\": preprocess,\n+            \"postprocess\": postprocess,\n+        }\n+    )\n+\n+    # Export the model from the model store to the local model folder\n+    bentoml.models.export_model(\n+        \"celestial_bodies_classifier_model:latest\",\n+        f\"{model_folder}/celestial_bodies_classifier_model.bentomodel\",\n+    )\n+\n     # Save the model history\n     np.save(model_folder / \"history.npy\", model.history.history)\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#update-srcevaluatepy","title":"Update <code>src/evaluate.py</code>","text":"<p>Update the <code>src/evaluate.py</code> file to load the model from BentoML:</p> src/evaluate.py<pre><code>import json\nimport sys\nfrom pathlib import Path\nfrom typing import List\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport bentoml\n\n\ndef get_training_plot(model_history: dict) -&gt; plt.Figure:\n    \"\"\"Plot the training and validation loss\"\"\"\n    epochs = range(1, len(model_history[\"loss\"]) + 1)\n\n    fig = plt.figure(figsize=(10, 4))\n    plt.plot(epochs, model_history[\"loss\"], label=\"Training loss\")\n    plt.plot(epochs, model_history[\"val_loss\"], label=\"Validation loss\")\n    plt.xticks(epochs)\n    plt.title(\"Training and validation loss\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.grid(True)\n\n    return fig\n\n\ndef get_pred_preview_plot(\n    model: tf.keras.Model, ds_test: tf.data.Dataset, labels: List[str]\n) -&gt; plt.Figure:\n    \"\"\"Plot a preview of the predictions\"\"\"\n    fig = plt.figure(figsize=(10, 5), tight_layout=True)\n    for images, label_idxs in ds_test.take(1):\n        preds = model.predict(images)\n        for i in range(10):\n            plt.subplot(2, 5, i + 1)\n            img = (images[i].numpy() * 255).astype(\"uint8\")\n            # Convert image to rgb if grayscale\n            if img.shape[-1] == 1:\n                img = np.squeeze(img, axis=-1)\n                img = np.stack((img,) * 3, axis=-1)\n            true_label = labels[label_idxs[i].numpy()]\n            pred_label = labels[np.argmax(preds[i])]\n            # Add red border if the prediction is wrong else add green border\n            img = np.pad(img, pad_width=((1, 1), (1, 1), (0, 0)))\n            if true_label != pred_label:\n                img[0, :, 0] = 255  # Top border\n                img[-1, :, 0] = 255  # Bottom border\n                img[:, 0, 0] = 255  # Left border\n                img[:, -1, 0] = 255  # Right border\n            else:\n                img[0, :, 1] = 255\n                img[-1, :, 1] = 255\n                img[:, 0, 1] = 255\n                img[:, -1, 1] = 255\n\n            plt.imshow(img)\n            plt.title(f\"True: {true_label}\\n\" f\"Pred: {pred_label}\")\n            plt.axis(\"off\")\n\n    return fig\n\n\ndef get_confusion_matrix_plot(\n    model: tf.keras.Model, ds_test: tf.data.Dataset, labels: List[str]\n) -&gt; plt.Figure:\n    \"\"\"Plot the confusion matrix\"\"\"\n    fig = plt.figure(figsize=(6, 6), tight_layout=True)\n    preds = model.predict(ds_test)\n\n    conf_matrix = tf.math.confusion_matrix(\n        labels=tf.concat([y for _, y in ds_test], axis=0),\n        predictions=tf.argmax(preds, axis=1),\n        num_classes=len(labels),\n    )\n\n    # Plot the confusion matrix\n    conf_matrix = conf_matrix / tf.reduce_sum(conf_matrix, axis=1)\n    plt.imshow(conf_matrix, cmap=\"Blues\")\n\n    # Plot cell values\n    for i in range(len(labels)):\n        for j in range(len(labels)):\n            value = conf_matrix[i, j].numpy()\n            if value == 0:\n                color = \"lightgray\"\n            elif value &gt; 0.5:\n                color = \"white\"\n            else:\n                color = \"black\"\n            plt.text(\n                j,\n                i,\n                f\"{value:.2f}\",\n                ha=\"center\",\n                va=\"center\",\n                color=color,\n                fontsize=8,\n            )\n\n    plt.colorbar()\n    plt.xticks(range(len(labels)), labels, rotation=90)\n    plt.yticks(range(len(labels)), labels)\n    plt.xlabel(\"Predicted label\")\n    plt.ylabel(\"True label\")\n    plt.title(\"Confusion matrix\")\n\n    return fig\n\n\ndef main() -&gt; None:\n    if len(sys.argv) != 3:\n        print(\"Arguments error. Usage:\\n\")\n        print(\"\\tpython3 evaluate.py &lt;model-folder&gt; &lt;prepared-dataset-folder&gt;\\n\")\n        exit(1)\n\n    model_folder = Path(sys.argv[1])\n    prepared_dataset_folder = Path(sys.argv[2])\n    evaluation_folder = Path(\"evaluation\")\n    plots_folder = Path(\"plots\")\n\n    # Create folders\n    (evaluation_folder / plots_folder).mkdir(parents=True, exist_ok=True)\n\n    # Load files\n    ds_test = tf.data.Dataset.load(str(prepared_dataset_folder / \"test\"))\n    labels = None\n    with open(prepared_dataset_folder / \"labels.json\") as f:\n        labels = json.load(f)\n\n    # Import the model to the model store from a local model folder\n    try:\n        bentoml.models.import_model(f\"{model_folder}/celestial_bodies_classifier_model.bentomodel\")\n    except bentoml.exceptions.BentoMLException:\n        print(\"Model already exists in the model store - skipping import.\")\n\n    # Load model\n    model = bentoml.keras.load_model(\"celestial_bodies_classifier_model\")\n    model_history = np.load(model_folder / \"history.npy\", allow_pickle=True).item()\n\n    # Log metrics\n    val_loss, val_acc = model.evaluate(ds_test)\n    print(f\"Validation loss: {val_loss:.2f}\")\n    print(f\"Validation accuracy: {val_acc * 100:.2f}%\")\n    with open(evaluation_folder / \"metrics.json\", \"w\") as f:\n        json.dump({\"val_loss\": val_loss, \"val_acc\": val_acc}, f)\n\n    # Save training history plot\n    fig = get_training_plot(model_history)\n    fig.savefig(evaluation_folder / plots_folder / \"training_history.png\")\n\n    # Save predictions preview plot\n    fig = get_pred_preview_plot(model, ds_test, labels)\n    fig.savefig(evaluation_folder / plots_folder / \"pred_preview.png\")\n\n    # Save confusion matrix plot\n    fig = get_confusion_matrix_plot(model, ds_test, labels)\n    fig.savefig(evaluation_folder / plots_folder / \"confusion_matrix.png\")\n\n    print(\n        f\"\\nEvaluation metrics and plot files saved at {evaluation_folder.absolute()}\"\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Check the differences with Git to better understand the changes:</p> Execute the following command(s) in a terminal<pre><code># Show the differences with Git\ngit diff src/evaluate.py\n</code></pre> <p>The output should be similar to this:</p> <pre><code>diff --git a/src/evaluate.py b/src/evaluate.py\nindex 3bca979..11322bd 100644\n--- a/src/evaluate.py\n+++ b/src/evaluate.py\n@@ -6,6 +6,7 @@ from typing import List\n import matplotlib.pyplot as plt\n import numpy as np\n import tensorflow as tf\n+import bentoml\n\n\n def get_training_plot(model_history: dict) -&gt; plt.Figure:\n@@ -128,9 +129,14 @@ def main() -&gt; None:\n     with open(prepared_dataset_folder / \"labels.json\") as f:\n         labels = json.load(f)\n\n+    # Import the model to the model store from a local model folder\n+    try:\n+        bentoml.models.import_model(f\"{model_folder}/celestial_bodies_classifier_model.bentomodel\")\n+    except bentoml.exceptions.BentoMLException:\n+        print(\"Model already exists in the model store - skipping import.\")\n+\n     # Load model\n-    model_path = model_folder / \"model.keras\"\n-    model = tf.keras.models.load_model(model_path)\n+    model = bentoml.keras.load_model(\"celestial_bodies_classifier_model\")\n     model_history = np.load(model_folder / \"history.npy\", allow_pickle=True).item()\n\n     # Log metrics\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#run-the-experiment","title":"Run the experiment","text":"Execute the following command(s) in a terminal<pre><code># Run the experiment. DVC will automatically run all required stages\ndvc repro\n</code></pre> <p>The experiment now uses BentoML to save and load the model. The resulting model is saved in the <code>model</code> folder and is automatically tracked by DVC. The model is then uploaded to the remote storage bucket when pushing the changes to DVC as well.</p> <p>You can check the models stored in the model store with the following command:</p> Execute the following command(s) in a terminal<pre><code># List the models in the model store\nbentoml models list\n</code></pre> <p>The output should look like this:</p> <pre><code> Tag                                                 Module                   Size      Creation Time\n celestial_bodies_classifier_model:o2bgmsfw3cov4aav  bentoml.keras  9.43 MiB  2024-12-10 10:23:48\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#check-the-changes","title":"Check the changes","text":"<p>Check the changes with Git to ensure that all the necessary files are tracked:</p> Execute the following command(s) in a terminal<pre><code># Add all the files\ngit add .\n\n# Check the changes\ngit status\n</code></pre> <p>The output should look like this.</p> <pre><code>On branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n    modified:   dvc.lock\n    modified:   requirements-freeze.txt\n    modified:   requirements.txt\n    modified:   src/evaluate.py\n    modified:   src/train.py\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#commit-the-changes-to-git","title":"Commit the changes to Git","text":"<p>Commit the changes to Git:</p> Execute the following command(s) in a terminal<pre><code># Commit the changes\ngit commit -m \"Use BentoML ton save and load the model\"\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#summary","title":"Summary","text":"<p>In this chapter, you have successfully:</p> <ol> <li>Installed BentoML</li> <li>Learned about BentoML's model store</li> <li>Updated and ran the experiment to use BentoML to save and load the model to    and from the model's store</li> </ol> <p>You did fix some of the previous issues:</p> <ul> <li> Model can be saved and loaded with all required artifacts for future usage</li> </ul> <p>You can now safely continue to the next chapter.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#state-of-the-mlops-process","title":"State of the MLOps process","text":"<ul> <li> Notebook has been transformed into scripts for production</li> <li> Codebase and dataset are versioned</li> <li> Steps used to create the model are documented and can be re-executed</li> <li> Changes done to a model can be visualized with parameters, metrics and       plots to identify differences between iterations</li> <li> Model can be saved and loaded with all required artifacts for future usage</li> <li> Model cannot be easily used from outside of the experiment context</li> </ul> <p>You will address these issues in the next chapters for improved efficiency and collaboration. Continue the guide to learn how.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-31-save-and-load-the-model-with-bentoml/#sources","title":"Sources","text":"<p>Highly inspired by:</p> <ul> <li>Quickstart - docs.bentoml.com</li> <li>Keras - docs.bentoml.com</li> <li>Model Store - docs.bentoml.com</li> <li>Bento and model APIs - docs.bentoml.com</li> <li>BentoML SDK - docs.bentoml.com</li> <li>BentoML CLI - docs.bentoml.com</li> </ul>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/","title":"Chapter 3.2 - Serve the model locally with BentoML","text":""},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#introduction","title":"Introduction","text":"<p>Now that the model is using  BentoML, enabling the extraction of metadata upon saving, you will serve the model with the help of  FastAPI to create local endpoints for interacting with the model.</p> <p>In this chapter, you will learn how to:</p> <ol> <li>Serve the model with BentoML and FastAPI</li> <li>Push the changes to DVC and Git</li> </ol> <p>The following diagram illustrates the control flow of the experiment at the end of this chapter:</p> <pre><code>flowchart TB\n    workspaceGraph &lt;-....-&gt; dot_git\n    data[data/raw]\n    subgraph cacheGraph[CACHE]\n        dot_dvc[(.dvc)]\n        dot_git[(.git)]\n    end\n    subgraph workspaceGraph[WORKSPACE]\n        data --&gt; code[*.py]\n        subgraph dvcGraph[\"dvc.yaml\"]\n            code\n        end\n        params[params.yaml] -.- code\n        subgraph bentoGraph[\" \"]\n            bento_model[classifier.bentomodel]\n            serve[serve.py] &lt;--&gt; bento_model\n            fastapi[FastAPI] &lt;--&gt; |bentoml serve serve:classifierService| serve\n        end\n        bento_model &lt;-.-&gt; dot_dvc\n        code &lt;--&gt; bento_model\n    end\n    subgraph browserGraph[BROWSER]\n        localhost &lt;--&gt; fastapi\n    end\n    style workspaceGraph opacity:0.4,color:#7f7f7f80\n    style dvcGraph opacity:0.4,color:#7f7f7f80\n    style cacheGraph opacity:0.4,color:#7f7f7f80\n    style data opacity:0.4,color:#7f7f7f80\n    style dot_git opacity:0.4,color:#7f7f7f80\n    style dot_dvc opacity:0.4,color:#7f7f7f80\n    style code opacity:0.4,color:#7f7f7f80\n    style params opacity:0.4,color:#7f7f7f80\n    linkStyle 0 opacity:0.4,color:#7f7f7f80\n    linkStyle 1 opacity:0.4,color:#7f7f7f80\n    linkStyle 2 opacity:0.4,color:#7f7f7f80\n    linkStyle 3 opacity:0.4,color:#7f7f7f80\n    linkStyle 4 opacity:0.4,color:#7f7f7f80\n    linkStyle 5 opacity:0.4,color:#7f7f7f80\n    linkStyle 6 opacity:0.4,color:#7f7f7f80\n    linkStyle 7 opacity:0.4,color:#7f7f7f80</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#steps","title":"Steps","text":""},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#create-the-bentoml-service","title":"Create the BentoML service","text":"<p>BentoML services allow to define the serving logic of machine learning models.</p> <p>A BentoML service is a class that defines all the endpoints and the logic to serve the model using FastAPI.</p> <p>Create a new file <code>src/serve.py</code> and add the following code:</p> src/serve.py<pre><code>from __future__ import annotations\nfrom bentoml.validators import ContentType\nfrom typing import Annotated\nfrom PIL.Image import Image\nfrom pydantic import Field\nimport bentoml\nimport json\n\n\n@bentoml.service(name=\"celestial_bodies_classifier\")\nclass CelestialBodiesClassifierService:\n    bento_model = bentoml.keras.get(\"celestial_bodies_classifier_model\")\n\n    def __init__(self) -&gt; None:\n        self.preprocess = self.bento_model.custom_objects[\"preprocess\"]\n        self.postprocess = self.bento_model.custom_objects[\"postprocess\"]\n        self.model = self.bento_model.load_model()\n\n    @bentoml.api()\n    def predict(\n            self,\n            image: Annotated[Image, ContentType(\"image/jpeg\")] = Field(description=\"Planet image to analyze\"),\n    ) -&gt; Annotated[str, ContentType(\"application/json\")]:\n        image = self.preprocess(image)\n\n        predictions = self.model.predict(image)\n\n        return json.dumps(self.postprocess(predictions))\n</code></pre> <p>This service will be used to serve the model with FastAPI and will do the following:</p> <ol> <li>The model is loaded from the BentoML model store</li> <li>The <code>preprocess</code> function is loaded from the model's custom objects</li> <li>The <code>postprocess</code> function is loaded from the model's custom objects</li> <li>The <code>predict</code> method is decorated with <code>@bentoml.api()</code> to create an endpoint</li> <li>The endpoint accepts an image as input</li> <li>The endpoint returns a JSON response</li> <li>The image is pre-processed</li> <li>The predictions are made from the model</li> <li>The predictions are post-processed and returned as a JSON string</li> </ol>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#serve-the-model","title":"Serve the model","text":"<p>Serve the model with the following command:</p> Execute the following command(s) in a terminal<pre><code># Serve the model\nbentoml serve --working-dir ./src serve:CelestialBodiesClassifierService\n</code></pre> <p>BentoML will load the model, create the FastAPI app and start it. You can then access the auto-generated model documentation on http://localhost:3000.</p> <p>The following endpoint has been created:</p> <ul> <li><code>/predict</code>: Upload a <code>png</code> or <code>jpg</code> image and get a prediction from the model.</li> </ul> <p>You can try out predictions by inputing some images to the model through the REST API!</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#try-out-the-prediction-endpoint","title":"Try out the prediction endpoint","text":"<p>The following images are available in the <code>extra-data</code> repository that you will use in a future chapter: https://github.com/swiss-ai-center/a-guide-to-mlops/tree/extra-data/extra_data.</p> <p>Here are some example you can use.</p> <p>Warning</p> <p>Please be aware that this model is for demonstration purposes. Some inputs may be incorrectly predicted.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#moon-example","title":"Moon example","text":"<p>Download the following image of the moon on your computer.</p> <p></p> <p>Upload it to the <code>/predict</code> endpoint and check the prediction.</p> <p>The output should be similar to this:</p> <pre><code>{\n  \"prediction\": \"Moon\",\n  \"probabilities\": {\n    \"Earth\": 1.5809072800854196e-12,\n    \"Jupiter\": 0.00019006800721399486,\n    \"MakeMake\": 0.025988487526774406,\n    \"Mars\": 0.05602957680821419,\n    \"Mercury\": 0.06992407888174057,\n    \"Moon\": 0.8260593414306641,\n    \"Neptune\": 0.000008633615834696684,\n    \"Pluto\": 0.014808151870965958,\n    \"Saturn\": 6.161330126652764e-13,\n    \"Uranus\": 9.311889357377368e-7,\n    \"Venus\": 0.006990684662014246\n  }\n}\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#makemake-example","title":"Makemake example","text":"<p>Download the following image of Makemake on your computer.</p> <p></p> <p>Upload it to the <code>/predict</code> endpoint and check the prediction.</p> <p>The output should be similar to this:</p> <pre><code>{\n  \"prediction\": \"MakeMake\",\n  \"probabilities\": {\n    \"Earth\": 3.275762878729438e-7,\n    \"Jupiter\": 0.07843036204576492,\n    \"MakeMake\": 0.5988457798957825,\n    \"Mars\": 0.0052123647183179855,\n    \"Mercury\": 0.173521026968956,\n    \"Moon\": 0.12065114825963974,\n    \"Neptune\": 0.009154518134891987,\n    \"Pluto\": 0.006169575732201338,\n    \"Saturn\": 7.211715455923695e-7,\n    \"Uranus\": 0.0000155931556946598,\n    \"Venus\": 0.007998582907021046\n  }\n}\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#neptune-example","title":"Neptune example","text":"<p>Download the following image of Neptune on your computer.</p> <p></p> <p>Upload it to the <code>/predict</code> endpoint and check the prediction.</p> <p>The output should be similar to this: You may notice the model got it wrong and predicted Uranus instead!</p> <pre><code>{\n  \"prediction\": \"Uranus\",\n  \"probabilities\": {\n    \"Earth\": 5.58305268683057e-9,\n    \"Jupiter\": 0.044645022600889206,\n    \"MakeMake\": 0.0007660466944798827,\n    \"Mars\": 0.002677031559869647,\n    \"Mercury\": 0.0006953442352823913,\n    \"Moon\": 0.0018753453623503447,\n    \"Neptune\": 0.3948681056499481,\n    \"Pluto\": 0.004337918013334274,\n    \"Saturn\": 0.0000032214618386205984,\n    \"Uranus\": 0.5497848987579346,\n    \"Venus\": 0.0003470888768788427\n  }\n}\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#check-the-changes","title":"Check the changes","text":"<p>Check the changes with Git to ensure that all the necessary files are tracked.</p> Execute the following command(s) in a terminal<pre><code># Add all the files\ngit add .\n\n# Check the changes\ngit status\n</code></pre> <p>The output should look like this.</p> <pre><code>On branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n    new file:   src/serve.py\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#commit-the-changes-to-git","title":"Commit the changes to Git","text":"<p>Commit the changes to Git.</p> Execute the following command(s) in a terminal<pre><code># Commit the changes\ngit commit -m \"Use BentoML to serve the model locally\"\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#check-the-results","title":"Check the results","text":"<p>Congratulations! You now have a model served over a REST API!</p> <p>This chapter is done, you can check the summary.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#summary","title":"Summary","text":"<p>In this chapter, you have successfully:</p> <ol> <li>Served the model with BentoML and FastAPI</li> <li>Pushed the changes to Git</li> </ol> <p>You did fix some of the previous issues:</p> <ul> <li> Model can be easily used outside of the experiment context</li> </ul> <p>You could serve this model from anywhere. Additional services could submit predictions to your model. The usage of FastAPI creates endpoints that are automatically documented to interact with the model.</p> <p>You can now safely continue to the next chapter.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#state-of-the-mlops-process","title":"State of the MLOps process","text":"<ul> <li> Notebook has been transformed into scripts for production</li> <li> Codebase and dataset are versioned</li> <li> Steps used to create the model are documented and can be re-executed</li> <li> Changes done to a model can be visualized with parameters, metrics and       plots to identify differences between iterations</li> <li> Model can be saved and loaded with all required artifacts for future usage</li> <li> Model cannot be easily used from outside of the experiment context</li> </ul> <p>You will address these issues in the next chapters for improved efficiency and collaboration. Continue the guide to learn how.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-32-serve-the-model-locally-with-bentoml/#sources","title":"Sources","text":"<p>Highly inspired by:</p> <ul> <li>Services - docs.bentoml.com</li> <li>Input and output types - docs.bentoml.com</li> <li>Containerization - docs.bentoml.com</li> <li>Build options - docs.bentoml.com</li> </ul>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/","title":"Chapter 3.3 - Build and publish the model with BentoML and Docker locally","text":""},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#introduction","title":"Introduction","text":"<p>Serving the model locally is great for testing purposes, but it is not sufficient for production. In this chapter, you will learn how to build and publish the model with  BentoML and  Docker.</p> <p>This will allow to share the model with others and deploy it later in a production environment.</p> <p>In this chapter, you will learn how to:</p> <ol> <li>Create a BentoML model artifact</li> <li>Containerize the model artifact with BentoML and Docker</li> <li>Test the containerized model artifact by serving it locally with Docker</li> </ol> <p>The following diagram illustrates the control flow of the experiment at the end of this chapter:</p> <pre><code>flowchart TB\n    workspaceGraph &lt;-....-&gt; dot_git\n    data[data/raw]\n    subgraph cacheGraph[CACHE]\n        dot_dvc[(.dvc)]\n        dot_git[(.git)]\n        bento_artifact[(Containerized\n                        artifact)]\n    end\n    subgraph workspaceGraph[WORKSPACE]\n        data --&gt; code[*.py]\n        subgraph dvcGraph[\"dvc.yaml\"]\n            code\n        end\n        params[params.yaml] -.- code\n        code &lt;--&gt; bento_model[classifier.bentomodel]\n        subgraph bentoGraph[bentofile.yaml]\n            bento_model\n            serve[serve.py] &lt;--&gt; bento_model\n            fastapi[FastAPI] &lt;--&gt; |bento serve|serve\n        end\n\n        bentoGraph --&gt;|bento build\n                       bento containerize| bento_artifact\n        bento_model &lt;-.-&gt; dot_dvc\n    end\n    subgraph browserGraph[BROWSER]\n        localhost &lt;--&gt; |docker run|bento_artifact\n        localhost &lt;--&gt; |bento serve| fastapi\n    end\n\n    style workspaceGraph opacity:0.4,color:#7f7f7f80\n    style dvcGraph opacity:0.4,color:#7f7f7f80\n    style cacheGraph opacity:0.4,color:#7f7f7f80\n    style data opacity:0.4,color:#7f7f7f80\n    style dot_git opacity:0.4,color:#7f7f7f80\n    style dot_dvc opacity:0.4,color:#7f7f7f80\n    style code opacity:0.4,color:#7f7f7f80\n    style serve opacity:0.4,color:#7f7f7f80\n    style bento_model opacity:0.4,color:#7f7f7f80\n    style fastapi opacity:0.4,color:#7f7f7f80\n    style params opacity:0.4,color:#7f7f7f80\n    linkStyle 0 opacity:0.4,color:#7f7f7f80\n    linkStyle 1 opacity:0.4,color:#7f7f7f80\n    linkStyle 2 opacity:0.4,color:#7f7f7f80\n    linkStyle 3 opacity:0.4,color:#7f7f7f80\n    linkStyle 4 opacity:0.4,color:#7f7f7f80\n    linkStyle 5 opacity:0.4,color:#7f7f7f80\n    linkStyle 6 opacity:0.4,color:#7f7f7f80\n    linkStyle 7 opacity:0.4,color:#7f7f7f80\n    linkStyle 8 opacity:0.4,color:#7f7f7f80</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#steps","title":"Steps","text":""},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#create-a-bentoml-model-artifact","title":"Create a BentoML model artifact","text":"<p>A BentoML model artifact (called \"Bento\" in the documentation) packages your model, code, and environment dependencies into a single file. It is the standard format for saving and sharing ML models.</p> <p>The BentoML model artifact is described in a <code>bentofile.yaml</code> file. It contains the following information:</p> <ul> <li>The service filename and class name</li> <li>The Python packages required to run the service</li> <li>The Docker configuration, such as the Python version to use</li> </ul> <p>Create a new <code>bentofile.yaml</code> file in the <code>src</code> directory with the following content:</p> src/bentofile.yaml<pre><code>service: 'serve:CelestialBodiesClassifierService'\ninclude:\n  - serve.py\npython:\n  packages:\n    - \"tensorflow==2.17.1\"\n    - \"matplotlib==3.9.3\"\n    - \"pillow==11.0.0\"\ndocker:\n    python_version: \"3.12\"\n</code></pre> <p>Do not forget to include the <code>serve.py</code> file in the BentoML model artifact. This file contains the code to serve the model with FastAPI as you have seen in the previous chapter.</p> <p>The <code>python</code> section contains the Python packages required to run the service. It does not contain DVC and other packages to build the model, as they are not required to run the service.</p> <p>The <code>docker</code> section contains the Python version to use. It is important to specify the Python version to ensure the service runs correctly.</p> <p>Now that the <code>bentofile.yaml</code> file is created, you can serve the model with the following command:</p> Execute the following command(s) in a terminal<pre><code># Serve the model\nbentoml serve --working-dir src\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#build-the-bentoml-model-artifact","title":"Build the BentoML model artifact","text":"<p>Before containerizing the BentoML model artifact with Docker, you need to build it.</p> <p>A BentoML model artifact can be built with the following command:</p> Execute the following command(s) in a terminal<pre><code># Build the BentoML model artifact\nbentoml build src\n</code></pre> <p>The output should be similar to this:</p> <pre><code>INFO: Adding current BentoML version to requirements.txt: bentoml==1.3.15\nINFO: Locking PyPI package versions.\n\n\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2557   \u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557   \u2588\u2588\u2588\u2557\u2588\u2588\u2557\n\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2551\u255a\u2550\u2550\u2588\u2588\u2554\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2551\n\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2554\u2588\u2588\u2557 \u2588\u2588\u2551   \u2588\u2588\u2551   \u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2588\u2588\u2554\u2588\u2588\u2551\u2588\u2588\u2551\n\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u255d  \u2588\u2588\u2551\u255a\u2588\u2588\u2557\u2588\u2588\u2551   \u2588\u2588\u2551   \u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2554\u255d\u2588\u2588\u2551\u2588\u2588\u2551\n\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551 \u255a\u2588\u2588\u2588\u2588\u2551   \u2588\u2588\u2551   \u255a\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2551 \u255a\u2550\u255d \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\n\u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u2550\u2550\u255d   \u255a\u2550\u255d    \u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u255d     \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\nSuccessfully built Bento(tag=\"celestial_bodies_classifier:v5rlmavw4kahqaav\").\n\nNext steps:\n\n* Deploy to BentoCloud:\n    $ bentoml deploy celestial_bodies_classifier:v5rlmavw4kahqaav -n ${DEPLOYMENT_NAME}\n\n* Update an existing deployment on BentoCloud:\n    $ bentoml deployment update --bento celestial_bodies_classifier:v5rlmavw4kahqaav ${DEPLOYMENT_NAME}\n\n* Containerize your Bento with `bentoml containerize`:\n    $ bentoml containerize celestial_bodies_classifier:v5rlmavw4kahqaav\n\n* Push to BentoCloud with `bentoml push`:\n    $ bentoml push celestial_bodies_classifier:v5rlmavw4kahqaav\n</code></pre> <p>All Bentos can be listed with the following command:</p> Execute the following command(s) in a terminal<pre><code># List all BentoML model artifacts\nbentoml list\n</code></pre> <p>The output should be similar to this:</p> <pre><code> Tag                                           Size       Model Size  Creation Time\n celestial_bodies_classifier:v5rlmavw4kahqaav  18.88 KiB  9.43 MiB    2024-12-10 11:37:00\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#containerize-the-bentoml-model-artifact-with-docker","title":"Containerize the BentoML model artifact with Docker","text":"<p>Now that the BentoML model artifact is built, you can containerize it with the following command:</p> Execute the following command(s) in a terminal<pre><code># Containerize the BentoML model artifact with Docker\nbentoml containerize celestial_bodies_classifier:latest --image-tag celestial-bodies-classifier:latest\n</code></pre> <p>The first <code>:latest</code> is the tag of the BentoML model artifact. It is a symlink to the latest version of the BentoML model artifact.</p> <p>The output should be similar to this:</p> <pre><code>INFO: Building OCI-compliant image for celestial_bodies_classifier:v5rlmavw4kahqaav with docker\n\n[+] Building 57.1s (17/17) FINISHED                                                                      docker:default\n =&gt; [internal] load build definition from Dockerfile                                                               0.1s\n =&gt; =&gt; transferring dockerfile: 1.92kB                                                                             0.0s\n =&gt; [internal] load metadata for docker.io/library/python:3.12-slim                                                2.3s\n =&gt; [internal] load .dockerignore                                                                                  0.0s\n =&gt; =&gt; transferring context: 2B                                                                                    0.0s\n =&gt; [base-container  1/12] FROM docker.io/library/python:3.12-slim@sha256:2b0079146a74e23bf4ae8f6a28e1b484c6292f6  3.6s\n =&gt; =&gt; resolve docker.io/library/python:3.12-slim@sha256:2b0079146a74e23bf4ae8f6a28e1b484c6292f6fb904cbb51825b4a1  0.0s\n =&gt; =&gt; sha256:bc0965b23a04fe7f2d9fb20f597008fcf89891de1c705ffc1c80483a1f098e4f 28.23MB / 28.23MB                   1.2s\n =&gt; =&gt; sha256:9b871d410cbf35a95adbe8c061f6d60e2e129bd2fd9b60485a8dd397ee3fcf61 3.32MB / 3.32MB                     1.1s\n =&gt; =&gt; sha256:8bfa778b5b231c44fb4d35b4783fe69f55f2b3f59dad4c8205661c3f752494a6 13.65MB / 13.65MB                   1.6s\n =&gt; =&gt; sha256:2b0079146a74e23bf4ae8f6a28e1b484c6292f6fb904cbb51825b4a19812fcd8 9.12kB / 9.12kB                     0.0s\n =&gt; =&gt; sha256:027e90762c20461da8dc5f530b0ca8604b38c382dadacb4471ea47377c7cf951 1.75kB / 1.75kB                     0.0s\n =&gt; =&gt; sha256:3ebf71e888419589c6cda9e15384dc2bff81338fb591f54af96ca5529df597c2 5.17kB / 5.17kB                     0.0s\n =&gt; =&gt; sha256:258b25b9265525eaafd659e18f862525eea9e6379dce2ef29defd91ba0b8868c 249B / 249B                         1.4s\n =&gt; =&gt; extracting sha256:bc0965b23a04fe7f2d9fb20f597008fcf89891de1c705ffc1c80483a1f098e4f                          1.3s\n =&gt; =&gt; extracting sha256:9b871d410cbf35a95adbe8c061f6d60e2e129bd2fd9b60485a8dd397ee3fcf61                          0.1s\n =&gt; =&gt; extracting sha256:8bfa778b5b231c44fb4d35b4783fe69f55f2b3f59dad4c8205661c3f752494a6                          0.6s\n =&gt; =&gt; extracting sha256:258b25b9265525eaafd659e18f862525eea9e6379dce2ef29defd91ba0b8868c                          0.0s\n =&gt; [internal] load build context                                                                                  0.1s\n =&gt; =&gt; transferring context: 9.91MB                                                                                0.0s\n =&gt; [base-container  2/12] RUN rm -f /etc/apt/apt.conf.d/docker-clean; echo 'Binary::apt::APT::Keep-Downloaded-Pa  0.5s\n =&gt; [base-container  3/12] RUN --mount=type=cache,target=/var/lib/apt --mount=type=cache,target=/var/cache/apt s  11.6s\n =&gt; [base-container  4/12] RUN curl -LO https://astral.sh/uv/install.sh &amp;&amp;     sh install.sh &amp;&amp; rm install.sh &amp;&amp;   2.8s\n =&gt; [base-container  5/12] RUN groupadd -g 1034 -o bentoml &amp;&amp; useradd -m -u 1034 -g 1034 -o -r bentoml             0.5s\n =&gt; [base-container  6/12] RUN mkdir /home/bentoml/bento &amp;&amp; chown bentoml:bentoml /home/bentoml/bento -R           0.5s\n =&gt; [base-container  7/12] WORKDIR /home/bentoml/bento                                                             0.1s\n =&gt; [base-container  8/12] COPY --chown=bentoml:bentoml ./env/python ./env/python/                                 0.2s\n =&gt; [base-container  9/12] RUN --mount=type=cache,target=/root/.cache/uv bash -euxo pipefail /home/bentoml/bento  29.7s\n =&gt; [base-container 10/12] COPY --chown=bentoml:bentoml . ./                                                       0.1s\n =&gt; [base-container 11/12] RUN rm -rf /var/lib/{apt,cache,log}                                                     0.2s\n =&gt; [base-container 12/12] RUN chmod +x /home/bentoml/bento/env/docker/entrypoint.sh                               0.7s\n =&gt; exporting to image                                                                                             4.1s\n =&gt; =&gt; exporting layers                                                                                            4.1s\n =&gt; =&gt; writing image sha256:09a34e0dd539e44331537b8ddb316e8b02e0a2c01d1d760ac225bed9ee1af6b0                       0.0s\n =&gt; =&gt; naming to docker.io/library/celestial-bodies-classifier:latest                                              0.0s\n\n 1 warning found (use docker --debug to expand):\n - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 6)\nSuccessfully built Bento container for \"celestial_bodies_classifier:latest\" with tag(s)\n\"celestial-bodies-classifier:latest\"\nTo run your newly built Bento container, run:\n    docker run --rm -p 3000:3000 celestial-bodies-classifier:latest\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#test-the-containerized-bentoml-model-artifact-locally","title":"Test the containerized BentoML model artifact locally","text":"<p>The BentoML model artifact is now containerized. To verify its behavior, serve the model artifact locally by running the Docker image:</p> Execute the following command(s) in a terminal<pre><code># Run the Docker image\ndocker run --rm -p 3000:3000 celestial-bodies-classifier:latest\n</code></pre> <p>Congrats! You have successfully containerized the BentoML model artifact using Docker. You have also tested the container by running it locally. The model is now ready to be shared on a container registry.</p>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#check-the-changes","title":"Check the changes","text":"<p>Check the changes with Git to ensure that all the necessary files are tracked:</p> Execute the following command(s) in a terminal<pre><code># Add all the files\ngit add .\n\n# Check the changes\ngit status\n</code></pre> <p>The output should look similar to this:</p> <pre><code>On branch main\nYour branch is up to date with 'origin/main'.\n\nChanges to be committed:\n(use \"git restore --staged &lt;file&gt;...\" to unstage)\n    new file:   src/bentofile.yaml\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#commit-the-changes-to-git","title":"Commit the changes to Git","text":"<p>Commit the changes to Git.</p> Execute the following command(s) in a terminal<pre><code># Commit the changes\ngit commit -m \"Use BentoML to containerize the model artifact\"\n</code></pre>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#summary","title":"Summary","text":"<p>Congratulations! You have successfully prepared the model for deployment in a production environment.</p> <p>In this chapter, you have successfully:</p> <ol> <li>Created and containerized a BentoML model artifact</li> </ol>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#state-of-the-mlops-process","title":"State of the MLOps process","text":"<ul> <li> Notebook has been transformed into scripts for production</li> <li> Codebase and dataset are versioned</li> <li> Steps used to create the model are documented and can be re-executed</li> <li> Changes done to a model can be visualized with parameters, metrics and       plots to identify differences between iterations</li> <li> Model can be saved and loaded with all required artifacts for future usage</li> <li> Model can be easily used outside of the experiment context</li> </ul>"},{"location":"part-3-serve-and-deploy-the-model/chapter-33-build-and-publish-the-model-with-bentoml-and-docker-locally/#sources","title":"Sources","text":"<p>Highly inspired by:</p> <ul> <li>Containerization - docs.bentoml.com</li> <li>Build options - docs.bentoml.com</li> </ul>"},{"location":"part-3-serve-and-deploy-the-model/conclusion/","title":"Conclusion","text":"<p>Congratulations! You did it!</p> <p>In this third part, you were able to move the model outside of the experiment context. The model is now saved and loaded with BentoML. You can serve the model locally.</p> <p>The model is now ready to be used in production.</p> <p>The following diagram illustrates the bricks you set up at the end of this part:</p> <pre><code>flowchart TB\n    workspaceGraph &lt;-....-&gt; dot_git\n    data[data/raw]\n    subgraph cacheGraph[CACHE]\n        dot_dvc[(.dvc)]\n        dot_git[(.git)]\n        bento_artifact[(Containerized\n                        artifact)]\n    end\n    subgraph workspaceGraph[WORKSPACE]\n        data --&gt; code[*.py]\n        subgraph dvcGraph[\"dvc.yaml\"]\n            code\n        end\n        params[params.yaml] -.- code\n        code &lt;--&gt; bento_model[classifier.bentomodel]\n        subgraph bentoGraph[bentofile.yaml]\n            bento_model\n            serve[serve.py] &lt;--&gt; bento_model\n            fastapi[FastAPI] &lt;--&gt; |bento serve|serve\n        end\n\n        bentoGraph --&gt;|bento build\n                       bento containerize| bento_artifact\n        bento_model &lt;-.-&gt; dot_dvc\n    end\n    subgraph browserGraph[BROWSER]\n        localhost &lt;--&gt; |docker run|bento_artifact\n        localhost &lt;--&gt; |bento serve| fastapi\n    end</code></pre> <p>The main goal of the MLOps process is to ensure that the model is reproducible, reliable and can be used in production. This goal is now achieved.</p>"},{"location":"part-3-serve-and-deploy-the-model/introduction/","title":"Introduction","text":"<p>Learn how to serve and deploy the model using  BentoML and  Docker.</p>"},{"location":"part-3-serve-and-deploy-the-model/introduction/#environment","title":"Environment","text":"<p>This guide has been written with  macOS and  Linux operating systems in mind. If you use  Windows, you might encounter issues. Please use the Windows Subsystem for Linux (WSL 2) for optimal results.</p> <p>For this part, you also need to have  Docker installed. Docker will be utilized for setting up and managing the container registry.</p>"}]}